# System Architecture

> **Comprehensive architectural documentation for the Genie Space Configuration Generator**
> 
> This document describes the system architecture, components, data flows, and best practices for generating and managing Databricks Genie spaces using LLMs.

## Table of Contents

1. [High-Level Flow](#high-level-flow)
2. [System Capabilities and Features](#system-capabilities-and-features)
3. [Project Structure](#project-structure)
4. [Output Schema](#output-schema)
5. [Component Details](#component-details)
   - [Instruction Formatting Layer (New in 2026)](#7-instruction-formatting-layer)
6. [Data Flow Diagram](#data-flow-diagram)
7. [Module Dependency Graph](#module-dependency-graph)
8. [Error Handling Flow](#error-handling-flow)
9. [Configuration Options](#configuration-options)
10. [Performance Characteristics](#performance-characteristics)
11. [Security Considerations](#security-considerations)
12. [Scripts and Utilities](#scripts-and-utilities)
13. [Extension Points](#extension-points)
14. [Testing Strategy](#testing-strategy)
15. [Monitoring and Debugging](#monitoring-and-debugging)
16. [Deployment Options](#deployment-options)
17. [Genie Space API Integration](#genie-space-api-integration)
18. [Best Practices and Design Principles](#best-practices-and-design-principles)
19. [Quick Reference](#quick-reference)

## High-Level Flow (Updated 2026 - Quality Assurance Pipeline)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP 1: DOMAIN EXTRACTION (P3)                    â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  DomainKnowledgeExtractor                                     â”‚ â”‚
â”‚  â”‚  Extracts from Requirements:                                  â”‚ â”‚
â”‚  â”‚  â€¢ Table Relationships (1:1, 1:N, N:1, N:M)                   â”‚ â”‚
â”‚  â”‚  â€¢ Business Metrics (formulas, KPIs, aggregations)            â”‚ â”‚
â”‚  â”‚  â€¢ Common Filters (status, dates, flags)                      â”‚ â”‚
â”‚  â”‚  â€¢ Business Terminology (glossary, acronyms)                  â”‚ â”‚
â”‚  â”‚  â€¢ Sample Queries with context                                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                STEP 2: ENHANCED PROMPT BUILDING (P1)                 â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  PromptBuilder + Domain Knowledge Injection                   â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚ 1. Inject Extracted Domain Knowledge                    â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ 2. Add SQL Quality Criteria (6-point checklist)         â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ 3. Add Few-Shot Examples (high vs low quality)          â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ 4. Add Instruction Guidelines (5 principles)            â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ 5. Add Join Specification Requirements                  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ 6. Combine: Context + Format + Enhanced Requirements    â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP 3: LLM GENERATION                            â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  DatabricksLLMClient                                          â”‚ â”‚
â”‚  â”‚  â€¢ Call foundation model with enhanced prompt                 â”‚ â”‚
â”‚  â”‚  â€¢ Generate configuration with reasoning                      â”‚ â”‚
â”‚  â”‚  â€¢ Parse and validate structure                               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         STEP 4: BENCHMARK EXTRACTION & SQL GENERATION (2026)         â”‚
â”‚                         Two-Pass Approach                            â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Pass 1: BenchmarkExtractor                                   â”‚ â”‚
â”‚  â”‚  â€¢ Extract all FAQ questions (100% coverage)                  â”‚ â”‚
â”‚  â”‚  â€¢ Extract sample queries with SQL                            â”‚ â”‚
â”‚  â”‚  â€¢ Merge into configuration (expected_sql: null for FAQs)     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Pass 2: BenchmarkSQLGenerator (NEW)                          â”‚ â”‚
â”‚  â”‚  â€¢ Filter benchmarks with expected_sql: null                  â”‚ â”‚
â”‚  â”‚  â€¢ Build focused prompt (tables + questions only)             â”‚ â”‚
â”‚  â”‚  â€¢ Generate SQL in batches (default: 10 questions/batch)      â”‚ â”‚
â”‚  â”‚  â€¢ Update configuration with complete SQL                     â”‚ â”‚
â”‚  â”‚  â†’ Benefit: Scales to 100+ benchmarks without token limits    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              STEP 5: SQL & INSTRUCTION VALIDATION (P2)               â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  SQLValidator                                                 â”‚ â”‚
â”‚  â”‚  â€¢ Syntax checking (sqlparse)                                 â”‚ â”‚
â”‚  â”‚  â€¢ Table reference validation                                 â”‚ â”‚
â”‚  â”‚  â€¢ Join pattern verification                                  â”‚ â”‚
â”‚  â”‚  â€¢ Quality checks (SELECT *, dates, division)                 â”‚ â”‚
â”‚  â”‚  â†’ Report: errors, warnings, severity levels                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  InstructionQualityScorer                                     â”‚ â”‚
â”‚  â”‚  â€¢ Specificity Score (40 pts): column/table names             â”‚ â”‚
â”‚  â”‚  â€¢ Structure Score (30 pts): markdown formatting              â”‚ â”‚
â”‚  â”‚  â€¢ Clarity Score (30 pts): no vague terms                     â”‚ â”‚
â”‚  â”‚  â†’ Report: scores, grades, suggestions                        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           STEP 6: COMPREHENSIVE CONFIG REVIEW (P3)                   â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  ConfigReviewAgent - 4-Dimension Quality Assessment           â”‚ â”‚
â”‚  â”‚                                                               â”‚ â”‚
â”‚  â”‚  1. SQL Validation Score (35%)                                â”‚ â”‚
â”‚  â”‚     â€¢ Syntax + table refs + joins + quality                   â”‚ â”‚
â”‚  â”‚  2. Instruction Quality Score (25%)                           â”‚ â”‚
â”‚  â”‚     â€¢ Average across all instructions                         â”‚ â”‚
â”‚  â”‚  3. Join Completeness Score (20%)                             â”‚ â”‚
â”‚  â”‚     â€¢ Coverage of required table relationships                â”‚ â”‚
â”‚  â”‚  4. Coverage Score (20%)                                      â”‚ â”‚
â”‚  â”‚     â€¢ Example queries per table                               â”‚ â”‚
â”‚  â”‚     â€¢ Benchmark questions                                     â”‚ â”‚
â”‚  â”‚     â€¢ SQL expressions                                         â”‚ â”‚
â”‚  â”‚                                                               â”‚ â”‚
â”‚  â”‚  â†’ Overall Score (0-100) + Pass/Fail + Detailed Issues        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         STEP 7: OUTPUT & UNITY CATALOG VALIDATION                    â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Final Configuration + Quality Reports                        â”‚ â”‚
â”‚  â”‚  â€¢ Configuration JSON                                         â”‚ â”‚
â”‚  â”‚  â€¢ Validation Report (SQL + Instructions)                     â”‚ â”‚
â”‚  â”‚  â€¢ Review Report (4-dimension scores + issues)                â”‚ â”‚
â”‚  â”‚  â€¢ Unity Catalog table/column validation                      â”‚ â”‚
â”‚  â”‚  â€¢ Interactive table replacement (catalog/schema/table)       â”‚ â”‚
â”‚  â”‚  â€¢ Ready for deployment                                       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Improvements:**
- **Priority 1**: Enhanced prompts with SQL criteria + few-shot examples + domain knowledge
- **Priority 2**: Automated SQL validation + instruction quality scoring
- **Priority 3**: Domain extraction + comprehensive 4-dimension review
- **Two-Pass Benchmarks (2026)**: Separate SQL generation for scalability (supports 100+ benchmarks)
- **Result**: 99/99 tests passing, production-ready quality assurance

## System Capabilities and Features

### Core Capabilities

1. **Automated Configuration Generation**
   - Leverages LLMs (Databricks Foundation Models or custom endpoints)
   - Generates production-ready Genie space configurations
   - Includes reasoning and confidence scores
   - Validates output against strict schemas

2. **Intelligent Prompt Engineering (Enhanced 2026)**
   - **Domain Knowledge Extraction**: Automatically extracts table relationships, metrics, filters, terminology
   - **Enhanced Prompts with Quality Criteria**: 6-point SQL checklist + few-shot examples + instruction guidelines
   - **Structured Context Injection**: Injects extracted domain knowledge as structured context
   - Incorporates best practices from curated documentation
   - Supports customizable input sources

3. **Multi-Layer Validation (New 2026)**
   - **Schema Validation**: Pydantic models ensure type safety
   - **SQL Validation (Priority 2)**: Syntax, tables, joins, quality patterns (SELECT *, dates, division)
   - **Instruction Quality Scoring (Priority 2)**: 3-dimension scoring (specificity, structure, clarity)
   - **Comprehensive Review (Priority 3)**: 4-dimension quality assessment with overall score
   - **Unity Catalog Validation**: Table and column existence checks
   - **Error handling**: Severity-based issues (critical, high, medium, low, info) with suggestions

4. **Complete API Integration**
   - Full Genie Spaces API support (2026 features)
   - Pagination for large space lists
   - Partial updates (title, description only)
   - Serialized space export (requires CAN EDIT)
   - Parent path for workspace organization
   - Trash (recoverable) vs permanent delete

5. **Configuration Transformation**
   - Automatic conversion to Databricks `serialized_space` format
   - Handles complex nested structures
   - Generates unique IDs for all components
   - Preserves relationships and metadata

### Key Features

#### Configuration Generation Features
- **Multiple LLM Support**: Foundation models and custom endpoints
- **Reasoning Output**: Understand why configurations were chosen
- **Confidence Scoring**: Assess configuration quality
- **Flexible Input**: Markdown requirements documents
- **Structured Output**: Valid JSON matching Genie API schema
- **Markdown-Formatted Instructions**: Auto-generated instructions use markdown for better structure and readability

#### Quality Assurance Features (New 2026)

**Priority 1: Enhanced Prompt Engineering**
- SQL Quality Criteria: 6-point checklist (column refs, joins, aggregations, filters, output)
- Few-Shot Examples: High vs low quality configurations
- Instruction Guidelines: 5 principles for clarity and specificity
- Join Specifications: Explicit relationship documentation
- Domain Knowledge Injection: Structured context from extracted knowledge

**Priority 2: Automated Validation**
- **SQL Validator**: Syntax + table/column + join patterns + quality checks
  - Detects: SELECT *, hard-coded dates, missing tables, incomplete joins, unsafe division
  - Severity levels: critical, high, medium, low, info
  - Actionable suggestions for each issue
- **Instruction Scorer**: 3-dimension quality scoring (0-100 scale)
  - Specificity (40 pts): Concrete column/table names, SQL patterns
  - Structure (30 pts): Markdown headers, lists, code blocks
  - Clarity (30 pts): No vague terms, actionable language
  - Letter grades (A-F) with improvement suggestions

**Priority 3: Domain Intelligence & Comprehensive Review**
- **Domain Extractor**: Extracts from requirements
  - Table relationships (1:1, 1:N, N:1, N:M)
  - Business metrics (formulas, aggregations, KPIs)
  - Common filters (status, dates, boolean flags)
  - Business terminology (glossary, acronyms)
  - Sample queries with context
- **Config Review Agent**: 4-dimension quality assessment
  - SQL Validation Score (35%)
  - Instruction Quality Score (25%)
  - Join Completeness Score (20%)
  - Coverage Score (20%)
  - Overall score (0-100) + pass/fail + detailed issues

**Test Coverage**: 83/83 tests passing
- Priority 1: 7 tests (enhanced prompts, join specs)
- Priority 2: 45 tests (SQL validation + instruction scoring)
- Priority 3: 31 tests (domain extraction + comprehensive review)

#### Space Management Features
- **Create**: New spaces with optional parent folder
- **Read**: Get space details with optional full configuration
- **Update**: Full or partial updates (title, description, config)
- **Delete**: Move to trash (recoverable) or permanent delete
- **List**: Paginated listing of all spaces

#### Developer Experience Features
- **CLI Tools**: Command-line scripts for all operations
- **Python API**: Comprehensive Python client library
- **Examples**: Ready-to-use example scripts
- **Validation**: Setup validation and table/column validation tools
- **Automation**: End-to-end workflow scripts
- **Documentation**: Comprehensive guides and references

### Supported Workflow Patterns

1. **One-Shot Generation + Creation**
   ```bash
   genie.py create --requirements data/requirements.md
   ```

2. **Manual Review + Editing**
   ```bash
   genie.py generate --requirements data/requirements.md  # Generate
   genie.py validate  # Validate (interactive fixes if needed)
   vim output/genie_space_config.json  # Edit if needed
   genie.py deploy  # Deploy
   ```

3. **Programmatic Python API**
   ```python
   from src.genie_space_client import create_genie_space_from_file
   result = create_genie_space_from_file('config.json')
   ```

4. **Iterative Management**
   ```python
   client = GenieSpaceClient()
   client.create_space(config)
   client.list_spaces()
   client.update_space(space_id, title="New Title")
   client.trash_space(space_id)
   ```

## Project Structure

```
.
â”œâ”€â”€ genie.py                        # ðŸŒŸ Unified CLI (main entry point)
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ .env.example                    # Example environment file
â”œâ”€â”€ README.md                       # User guide
â”œâ”€â”€ ARCHITECTURE.md                 # This file - System architecture
â”œâ”€â”€ CONVERSION_PIPELINE.md          # Requirements conversion guide
â”œâ”€â”€ SIMPLIFIED_WORKFLOW.md          # Simplified workflow details
â”‚
â”œâ”€â”€ databricks.yml                  # Asset bundle configuration
â”œâ”€â”€ app.yaml                        # Databricks App runtime configuration
â”‚
â”œâ”€â”€ backend/                        # ðŸŒŸ FastAPI backend (Web UI Mode)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                     # FastAPI app entry point
â”‚   â”œâ”€â”€ services/                   # Business logic services
â”‚   â”‚   â”œâ”€â”€ job_tasks.py            # Job task orchestration
â”‚   â”‚   â”œâ”€â”€ job_manager.py          # Job execution manager
â”‚   â”‚   â”œâ”€â”€ file_storage_base.py    # ðŸ†• Abstract base for file storage
â”‚   â”‚   â”œâ”€â”€ file_storage.py         # Local file storage implementation
â”‚   â”‚   â”œâ”€â”€ session_store_base.py   # ðŸ†• Abstract base for session storage
â”‚   â”‚   â”œâ”€â”€ session_store.py        # SQLite session storage implementation
â”‚   â”‚   â”œâ”€â”€ benchmark_validator.py  # Benchmark validation
â”‚   â”‚   â””â”€â”€ validators.py           # Validation services
â”‚   â”œâ”€â”€ middleware/                 # Request middleware
â”‚   â”‚   â””â”€â”€ auth.py                 # Databricks authentication
â”‚   â”œâ”€â”€ storage/                    # Data storage (local files & SQLite)
â”‚   â”‚   â”œâ”€â”€ uploads/                # User-uploaded files
â”‚   â”‚   â””â”€â”€ sessions.db             # SQLite session database
â”‚   â””â”€â”€ requirements.txt            # Backend Python dependencies
â”‚
â”œâ”€â”€ frontend/                       # ðŸŒŸ Next.js UI application (Web UI Mode)
â”‚   â”œâ”€â”€ app/                        # Next.js pages and routing
â”‚   â”œâ”€â”€ components/                 # React components
â”‚   â”‚   â”œâ”€â”€ wizard/                 # Multi-step wizard components
â”‚   â”‚   â””â”€â”€ session/                # Session management components
â”‚   â”œâ”€â”€ lib/                        # Utilities and hooks
â”‚   â”œâ”€â”€ package.json                # Frontend dependencies
â”‚   â””â”€â”€ tsconfig.json               # TypeScript configuration
â”‚
â”œâ”€â”€ genie/                          # Core source code (Python package)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py                   # Pydantic models for Genie space config
â”‚   â”œâ”€â”€ pipeline/                   # ðŸŒŸ Pipeline orchestration
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ generator.py            # Configuration generation (7-step pipeline)
â”‚   â”‚   â”œâ”€â”€ validator.py            # Unity Catalog table validation
â”‚   â”‚   â”œâ”€â”€ deployer.py             # Space deployment
â”‚   â”‚   â”œâ”€â”€ parser.py               # Document parsing (async/concurrent)
â”‚   â”‚   â””â”€â”€ reviewer.py             # ðŸ†• Comprehensive config review (P3)
â”‚   â”œâ”€â”€ api/                        # API clients
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ genie_space_client.py   # Genie Space API client
â”‚   â”œâ”€â”€ llm/                        # LLM clients
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ databricks_llm.py       # Databricks LLM client
â”‚   â”œâ”€â”€ prompt/                     # Prompt management
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ prompt_builder.py       # ðŸ†• Prompt construction + domain injection (P1, P3)
â”‚   â”‚   â””â”€â”€ templates/              # Prompt templates
â”‚   â”‚       â”œâ”€â”€ curate_effective_genie.md         # Best practices
â”‚   â”‚       â”œâ”€â”€ genie_api.md                      # API documentation
â”‚   â”‚       â”œâ”€â”€ guide_prompt_with_reasoning.md    # ðŸ†• Enhanced prompt (P1)
â”‚   â”‚       â””â”€â”€ benchmark_sql_prompt.md           # ðŸ†• Benchmark SQL generation prompt (2026)
â”‚   â”œâ”€â”€ parsing/                    # Requirements parsing
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ pdf_parser.py           # PDF extraction
â”‚   â”‚   â”œâ”€â”€ markdown_parser.py      # Markdown extraction
â”‚   â”‚   â”œâ”€â”€ requirements_structurer.py  # Data models & structuring
â”‚   â”‚   â”œâ”€â”€ llm_enricher.py         # LLM-based enrichment
â”‚   â”‚   â”œâ”€â”€ markdown_generator.py   # Markdown output generation
â”‚   â”‚   â””â”€â”€ feedback_parser.py      # ðŸ†• Feedback analysis parser
â”‚   â”œâ”€â”€ benchmark/                  # ðŸ†• Benchmark extraction & SQL generation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ benchmark_extractor.py  # Benchmark extractor (100% FAQ coverage)
â”‚   â”‚   â”œâ”€â”€ benchmark_loader.py     # Load benchmarks from JSON files
â”‚   â”‚   â””â”€â”€ benchmark_sql_generator.py  # Two-pass benchmark SQL generation (2026)
â”‚   â”œâ”€â”€ extractor/                  # ðŸ†• Domain & content extraction
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ domain_extractor.py     # Domain knowledge extractor (P3)
â”‚   â”‚   â”œâ”€â”€ example_extractor.py    # Example SQL query extractor
â”‚   â”‚   â””â”€â”€ table_extractor.py      # Table information extractor
â”‚   â”œâ”€â”€ validation/                 # ðŸ†• Validation & scoring
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ sql_validator.py        # SQL syntax & quality validator (P2)
â”‚   â”‚   â”œâ”€â”€ instruction_scorer.py   # Instruction quality scorer (P2)
â”‚   â”‚   â””â”€â”€ table_validator.py      # Unity Catalog table & column validator
â”‚   â””â”€â”€ utils/                      # Utility modules
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config_transformer.py   # Config transformation
â”‚       â””â”€â”€ parse_cache.py          # Parse result caching
â”‚
â”œâ”€â”€ sample/                         # ðŸ†• Sample data and examples
â”‚   â”œâ”€â”€ inputs/                     # Sample input requirements
â”‚   â”‚   â””â”€â”€ demo_requirements.md    # Fashion retail demo requirements
â”‚   â””â”€â”€ benchmarks/                 # Sample benchmark questions
â”‚       â””â”€â”€ benchmarks.json         # Structured benchmark questions
â”‚
â”œâ”€â”€ output/                         # Generated files (gitignored)
â”‚   â”œâ”€â”€ genie_space_config.json     # Generated config
â”‚   â””â”€â”€ genie_space_result.json     # Creation result
â”‚
â”œâ”€â”€ scripts/                        # Utility scripts
â”‚   â”œâ”€â”€ validate_setup.py           # Environment validation
â”‚   â”œâ”€â”€ convert_requirements.py     # Requirements conversion
â”‚   â”œâ”€â”€ auto_deploy.py              # ðŸ†• Automated deployment with catalog replacement
â”‚   â”œâ”€â”€ analyze_feedback.py         # ðŸ†• Genie Space feedback analysis
â”‚   â””â”€â”€ export_feedback_csv.py      # ðŸ†• Export feedback to CSV
â”‚
â””â”€â”€ tests/                          # Test suite (all passing âœ…)
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ conftest.py                 # Pytest fixtures and configuration
    â”œâ”€â”€ test_generation.py          # Generation tests
    â”œâ”€â”€ test_generation_domain.py   # Domain-aware generation tests
    â”œâ”€â”€ test_example_usage.py       # Example usage tests
    â”œâ”€â”€ test_join_specs.py          # Join specification tests
    â”œâ”€â”€ test_requirements_converter.py  # Requirements conversion tests
    â”œâ”€â”€ test_requirements_domain.py # Domain extraction from requirements
    â”œâ”€â”€ test_table_validator.py     # Table validator tests
    â”œâ”€â”€ test_benchmark_extraction.py    # Benchmark extraction tests
    â”œâ”€â”€ test_benchmark_integration.py   # Benchmark integration tests
    â”œâ”€â”€ test_benchmark_loader.py        # Benchmark loader tests
    â”œâ”€â”€ test_benchmark_sql_generator.py # Benchmark SQL generation tests
    â”œâ”€â”€ test_enhanced_generation.py # P1: Enhanced prompts tests
    â”œâ”€â”€ test_sql_validator.py       # P2: SQL validation tests
    â”œâ”€â”€ test_instruction_scorer.py  # P2: Instruction scoring tests
    â”œâ”€â”€ test_domain_extractor.py    # P3: Domain extraction tests
    â”œâ”€â”€ test_example_extractor.py   # Example query extraction tests
    â”œâ”€â”€ test_reviewer.py            # P3: Config review tests
    â”œâ”€â”€ test_enhanced_parsing.py    # ðŸ†• Enhanced parsing Phase 1 tests (26 tests)
    â””â”€â”€ test_phase2_parsing.py      # ðŸ†• Enhanced parsing Phase 2 tests (20 tests)
```

**Key Changes in Structure:**
- ðŸŒŸ **genie.py**: Unified CLI (main entry point) that combines parse, generate, validate, and deploy
- ðŸŒŸ **genie/pipeline/**: Orchestration layer with generator, validator, deployer, and parser modules
  - **parser.py**: Async/concurrent document parsing module with progress tracking and caching
- **genie/parsing/**: Complete requirements parsing pipeline (PDF, Markdown, structuring, enrichment)
- ðŸ†• **genie/benchmark/**: Benchmark extraction, loading, and SQL generation (modular)
- ðŸ†• **genie/extractor/**: Domain knowledge, example queries, and table extraction (modular)
- ðŸ†• **genie/validation/**: SQL validation, instruction scoring, and table validation (modular)
- ðŸ†• **sample/**: Sample data directory with demo requirements and benchmarks

### Modular Reorganization (2026)

The codebase has been refactored into a more modular structure for better maintainability and clarity:

**Before (monolithic `genie/utils/`):**
```
genie/utils/
â”œâ”€â”€ benchmark_extractor.py
â”œâ”€â”€ benchmark_sql_generator.py
â”œâ”€â”€ domain_extractor.py
â”œâ”€â”€ example_extractor.py
â”œâ”€â”€ table_extractor.py
â”œâ”€â”€ sql_validator.py
â”œâ”€â”€ instruction_scorer.py
â”œâ”€â”€ table_validator.py
â”œâ”€â”€ config_transformer.py
â””â”€â”€ parse_cache.py
```

**After (organized by domain):**
```
genie/
â”œâ”€â”€ benchmark/              # Benchmark-related functionality
â”‚   â”œâ”€â”€ benchmark_extractor.py
â”‚   â”œâ”€â”€ benchmark_loader.py
â”‚   â””â”€â”€ benchmark_sql_generator.py
â”œâ”€â”€ extractor/              # Content extraction
â”‚   â”œâ”€â”€ domain_extractor.py
â”‚   â”œâ”€â”€ example_extractor.py
â”‚   â””â”€â”€ table_extractor.py
â”œâ”€â”€ validation/             # Validation and scoring
â”‚   â”œâ”€â”€ sql_validator.py
â”‚   â”œâ”€â”€ instruction_scorer.py
â”‚   â””â”€â”€ table_validator.py
â””â”€â”€ utils/                  # True utilities
    â”œâ”€â”€ config_transformer.py
    â””â”€â”€ parse_cache.py
```

**Benefits:**
- **Clear Separation of Concerns**: Each directory has a single responsibility
- **Easier Navigation**: Related modules are grouped together
- **Better Testability**: Modular structure makes testing easier
- **Improved Maintainability**: Changes are localized to specific domains
- **Logical Imports**: `from src.benchmark import ...`, `from src.validation import ...`

**Sample Data Organization:**
```
sample/
â”œâ”€â”€ inputs/                 # Sample requirements
â”‚   â””â”€â”€ demo_requirements.md
â””â”€â”€ benchmarks/             # Sample benchmarks
    â””â”€â”€ benchmarks.json
```

This provides a clear separation between production code and example/demo data.

## Output Schema

The generated configuration follows this structure:

```json
{
  "genie_space_config": {
    "space_name": "Your Analytics Space",
    "description": "Natural language querying for your data",
    "purpose": "Enable business users to analyze data",
    "tables": [
      {
        "catalog_name": "your_catalog",
        "schema_name": "your_schema",
        "table_name": "your_table",
        "description": "Table description"
      }
    ],
    "joins": [
      {
        "left_table": "your_catalog.your_schema.table1",
        "left_alias": "table1",
        "right_table": "your_catalog.your_schema.table2",
        "right_alias": "table2",
        "join_condition": "`table1`.`id` = `table2`.`id`",
        "relationship_type": "FROM_RELATIONSHIP_TYPE_MANY_TO_ONE"
      }
    ],
    "instructions": [
      {
        "content": "General instructions for querying..."
      }
    ],
    "example_sql_queries": [
      {
        "question": "Example question",
        "sql_query": "SELECT column FROM ...",
        "description": "Query description"
      }
    ],
    "sql_expressions": [
      {
        "name": "metric_name",
        "expression": "SUM(column)",
        "description": "Metric description",
        "type": "metric"
      }
    ],
    "benchmark_questions": [
      {
        "question": "Test question"
      }
    ],
    "enable_data_sampling": true
  },
  "reasoning": "LLM's explanation for configuration choices...",
  "confidence_score": 0.95
}
```

**Schema Components:**
- **genie_space_config**: Main configuration object
  - **space_name**: Display name for the Genie space
  - **description**: Brief description of the space purpose
  - **purpose**: Detailed explanation of space objectives
  - **tables**: List of Unity Catalog tables to include
  - **joins**: Explicit join specifications between tables
  - **instructions**: Text instructions guiding the AI assistant (supports markdown formatting)
  - **example_sql_queries**: Example questions with SQL answers
  - **sql_expressions**: Reusable metrics, filters, and dimensions
  - **benchmark_questions**: Test questions for validation
  - **enable_data_sampling**: Whether to enable data sampling (boolean)
- **reasoning**: Optional explanation of configuration choices from the LLM
- **confidence_score**: Optional confidence score (0.0-1.0)

**Markdown-Formatted Instructions (New in 2026):**
Instructions now support markdown formatting for better structure and readability:
- Section headings (`##`) organize related instructions
- Bullet lists (`-`) for multiple related points
- **Bold** text for emphasis on critical terms
- Inline `code` for column/table names
- Numbered lists for sequential steps
- Blockquotes (`>`) for clarification questions

This improves instruction clarity and makes configurations more maintainable.

**Transformation:** This user-friendly format is automatically transformed to Databricks' internal `serialized_space` format when creating or updating spaces. See [Configuration Format Transformation](#configuration-format-transformation) for details.

## Component Details

### 1. Input Layer

**Purpose**: Provide comprehensive context for LLM generation

**Components**:
- `genie/prompt/templates/curate_effective_genie.md`: Best practices and principles
- `genie/prompt/templates/genie_api.md`: API documentation and schema information
- `sample/inputs/demo_requirements.md`: Example business requirements (Fashion Retail Analytics demo)

**Format**: Markdown documents with structured information

### 2. Prompt Builder Layer (Enhanced 2026)

**Class**: `PromptBuilder`

**Responsibilities**:
```python
class PromptBuilder:
    def __init__(context_doc, output_doc, input_data):
        # Store document paths

    def _read_file(path) -> str:
        # Read file contents

    def build_prompt() -> str:
        # Build basic prompt

    def build_prompt_with_reasoning(domain_knowledge=None) -> str:
        # ðŸ†• Build prompt with reasoning + domain knowledge injection (P1, P3)
```

**Process (Enhanced)**:
1. Extract domain knowledge from requirements (P3)
2. Read all input documents
3. Inject domain knowledge as structured context
4. Add SQL quality criteria (P1)
5. Add few-shot examples (P1)
6. Add instruction guidelines (P1)
7. Construct comprehensive prompt
8. Format for optimal LLM comprehension

**Enhanced Prompt Template** (`guide_prompt_with_reasoning.md`):
- **SQL Quality Criteria**: 6-point checklist for correct SQL generation
- **Few-Shot Examples**: High vs low quality configurations
- **Instruction Guidelines**: 5 principles for clear, specific instructions
- **Join Specifications**: Requirements for explicit table relationships
- **Domain Knowledge Context**: Extracted relationships, metrics, filters, terminology

### 3. LLM Client Layer

**Classes**: 
- `DatabricksLLMClient` (for custom endpoints)
- `DatabricksFoundationModelClient` (for foundation models)

**Responsibilities**:
```python
class DatabricksLLMClient:
    def __init__(endpoint_name, host, token):
        # Initialize connection
    
    def _make_request(prompt, max_tokens, temperature):
        # Make API request
    
    def generate(prompt) -> str:
        # Generate raw text
    
    def generate_genie_config(prompt) -> LLMResponse:
        # Generate and parse config
```

**Features**:
- Authentication with Databricks
- Request formatting
- Response parsing
- Error handling
- JSON extraction

### 4. Validation Layer

**Models** (Pydantic):

```python
# Main configuration
GenieSpaceConfig
â”œâ”€â”€ space_name: str
â”œâ”€â”€ description: str
â”œâ”€â”€ purpose: str
â”œâ”€â”€ tables: List[GenieSpaceTable]
â”‚   â””â”€â”€ catalog_name, schema_name, table_name
â”œâ”€â”€ instructions: List[GenieSpaceInstruction]
â”‚   â””â”€â”€ content, priority
â”œâ”€â”€ example_sql_queries: List[GenieSpaceExampleSQL]
â”‚   â””â”€â”€ question, sql_query, description
â”œâ”€â”€ sql_snippets: Optional[GenieSpaceSQLSnippets]
â”‚   â”œâ”€â”€ filters: List[GenieSpaceSQLFilter]
â”‚   â”‚   â””â”€â”€ sql, display_name, synonyms
â”‚   â”œâ”€â”€ expressions: List[GenieSpaceSQLExpression]
â”‚   â”‚   â””â”€â”€ alias, sql, display_name, synonyms, instruction
â”‚   â””â”€â”€ measures: List[GenieSpaceSQLMeasure]
â”‚       â””â”€â”€ alias, sql, display_name, synonyms, instruction
â””â”€â”€ benchmark_questions: List[GenieSpaceBenchmark]
    â””â”€â”€ question, expected_sql

# Response wrapper
LLMResponse
â”œâ”€â”€ genie_space_config: GenieSpaceConfig
â”œâ”€â”€ reasoning: Optional[str]
â””â”€â”€ confidence_score: Optional[float]
```

**Validation**:
- Type checking (automatic)
- Required field verification
- Data structure validation
- Custom constraints

### 5. Document Parsing Layer (Enhanced 2026)

**Module**: `genie/pipeline/parser.py`

**Responsibilities**:
```python
async def parse_documents_async(
    input_dir: str,
    output_path: str = "data/parsed_requirements.md",
    llm_model: str = "databricks-gpt-5-2",
    vision_model: str = "databricks-claude-sonnet-4",
    use_llm: bool = True,
    domain: str = "combined",
    databricks_host: Optional[str] = None,
    databricks_token: Optional[str] = None,
    verbose: bool = True,
    max_concurrent_pdfs: int = 3
) -> Dict[str, Any]:
    # Parse PDFs and markdown files into structured requirements

def parse_documents(...):
    # Synchronous wrapper for async parsing
```

**Process**:
1. Extract content from PDF files (async/concurrent)
   - Uses vision model for image-based parsing
   - Configurable concurrency (default: 3 concurrent PDFs)
   - Per-page processing (2.21x faster based on benchmarks)
   - Progress bars via `tqdm` for real-time feedback
2. Extract content from Markdown files (regex-based)
3. Structure and combine data using `RequirementsStructurer`
4. **Phase 1 Enhanced Extraction** (NEW):
   - Column metadata (is_required, usage_type, transformation_rule)
   - Table remarks (special notes, restrictions)
   - SQL aggregation patterns (CTEs, UNION, COALESCE)
   - Filtering rules (WHERE conditions)
   - JOIN specifications (explicit syntax with conditions)
5. **Phase 2 Enhanced Extraction** (NEW):
   - Formula library (DAU, ARPU, Retention Rate patterns)
   - Platform-specific logic (PUBG, Steam, Discord, InZOI)
   - Query analysis (intent, complexity, optimization notes)
   - Result examples (sample data for validation)
6. Optional LLM enrichment via `LLMEnricher`
7. Generate output markdown via `MarkdownGenerator`

**Features**:
- Async/concurrent PDF processing with semaphore control
- Vision model integration (`databricks-claude-sonnet-4`)
- Real-time progress tracking with `tqdm_asyncio`
- Automatic error handling and recovery
- Supports multiple domain types (social_analytics, kpi_analytics, combined)
- Environment variable support for credentials
- **Enhanced metadata extraction** (90%+ reduction in information loss)
- **Formula pattern detection** (7 known patterns: DAU, MAU, ARPU, etc.)
- **Platform-specific logic analysis** (restrictions, transformations, requirements)

**Output**: Structured markdown file containing:
- Questions (categorized by domain)
- Tables with descriptions and remarks
- SQL queries with enhanced context (patterns, filters, joins)
- **Column Details** section (required/optional, usage types, transformations)
- **Join Relationships** section (explicit JOIN syntax)
- **Aggregation Patterns** section (CTEs, UNION, window functions)
- **Formula Library** section (reusable metric definitions)
- **Platform Logic** section (platform-specific notes)
- **Query Analysis** section (intent, complexity, optimization)
- Metadata about extracted content

**Data Models** (see `genie/parsing/requirements_structurer.py`):

```python
@dataclass
class ColumnInfo:
    name: str
    description: Optional[str] = None
    data_type: Optional[str] = None
    is_required: bool = True  # Phase 1: False if marked "optional"
    usage_type: Optional[str] = None  # Phase 1: filtering, display, aggregation, join_key
    transformation_rule: Optional[str] = None  # Phase 1: e.g., "FROM_UNIXTIME(timestamp)"

@dataclass
class TableInfo:
    catalog: str
    schema: str
    table: str
    description: str
    columns: List[ColumnInfo] = field(default_factory=list)
    related_kpi: Optional[str] = None
    sample_query: Optional[str] = None
    table_remarks: List[str] = field(default_factory=list)  # Phase 1: special notes

@dataclass
class SQLQuery:
    question_id: str
    query: str
    description: str
    tables_used: List[str] = field(default_factory=list)
    # Phase 1 fields
    aggregation_patterns: List[str] = field(default_factory=list)
    filtering_rules: List[str] = field(default_factory=list)
    join_specs: List[str] = field(default_factory=list)
    # Phase 2 fields
    intent: Optional[str] = None  # monitoring, analysis, reporting
    complexity: Optional[str] = None  # simple, medium, high
    optimization_notes: List[str] = field(default_factory=list)
    result_example: Optional[QueryResultExample] = None

@dataclass
class FormulaDefinition:  # Phase 2
    name: str  # DAU, ARPU, Retention Rate, etc.
    formula: str  # SQL expression
    description: str
    required_columns: List[str] = field(default_factory=list)
    notes: Optional[str] = None

@dataclass
class PlatformNote:  # Phase 2
    platform: str  # PUBG, Steam, Discord, InZOI
    note_type: str  # restriction, requirement, transformation, limitation
    description: str
    affected_tables: List[str] = field(default_factory=list)
    example_code: Optional[str] = None
```

**Phase 1 + Phase 2 Results** (Validated on real_requirements/inputs):
- Documentation growth: **355 â†’ 1,855 lines** (5.2x increase)
- Column metadata: **100% loss â†’ <10% loss** (captures optional markers, usage types)
- SQL patterns: **70% loss â†’ <15% loss** (captures CTEs, UNION, aggregations)
- JOIN specs: **85% loss â†’ <15% loss** (explicit syntax captured)
- Platform notes: **31 extracted** (device options, platform restrictions, user types)
- Formula patterns: **Infrastructure complete** (ready for pattern tuning)
- Test coverage: **46/46 tests passing** (26 Phase 1 + 20 Phase 2)

### 6. Table & Column Validation Layer

**Class**: `TableValidator`

**Responsibilities**:
```python
class TableValidator:
    def __init__(databricks_host, databricks_token):
        # Initialize connection to Unity Catalog
    
    def validate_table(catalog, schema, table) -> bool:
        # Verify table exists
    
    def validate_columns(catalog, schema, table, columns) -> Dict[str, bool]:
        # Verify columns exist in table
    
    def get_table_schema(catalog, schema, table) -> Dict:
        # Fetch table schema from Unity Catalog
    
    def validate_config(config_path) -> ValidationReport:
        # Validate entire configuration
```

**Process**:
1. Parse configuration file
2. Extract table and column references
3. Query Unity Catalog API for table schemas
4. Validate all tables exist and are accessible
5. Validate all columns exist in their tables
6. Generate comprehensive validation report

**Features**:
- Unity Catalog API integration
- Fallback to SQL DESCRIBE TABLE
- Schema caching for performance
- Case-insensitive column matching
- Detailed error reporting
- JSON and human-readable output

**Output**: `ValidationReport`
```python
ValidationReport
â”œâ”€â”€ tables_checked: List[str]
â”œâ”€â”€ tables_valid: List[str]
â”œâ”€â”€ tables_invalid: List[str]
â”œâ”€â”€ columns_checked: Dict[str, List[str]]
â”œâ”€â”€ columns_valid: Dict[str, List[str]]
â”œâ”€â”€ columns_invalid: Dict[str, List[str]]
â””â”€â”€ issues: List[ValidationIssue]
    â”œâ”€â”€ severity: "error" | "warning" | "info"
    â”œâ”€â”€ type: str
    â”œâ”€â”€ message: str
    â”œâ”€â”€ table: Optional[str]
    â”œâ”€â”€ column: Optional[str]
    â””â”€â”€ location: Optional[str]
```

### 7. Instruction Formatting Layer

**Purpose**: Generate well-structured, markdown-formatted instructions for better readability and organization

**Markdown Elements Supported**:

```python
# Section Headings
"## Date and Time Handling"
"## Metric Calculations"
"## Clarification Questions"

# Bullet Lists
"- Always use `event_date` column for date-based queries"
"- Default to **last 30 days** when no time period is specified"

# Bold Emphasis
"**revenue metrics**"
"**last 30 days**"

# Inline Code
"`event_date`"
"`total_revenue`"
"`status != 'cancelled'`"

# Numbered Lists
"1. Use `total_revenue` column (already includes tax)"
"2. Round all monetary values to 2 decimal places"

# Blockquotes (for clarification questions)
"> \"To analyze performance, please specify: (1) time period, (2) product category\""
```

**Example Well-Formatted Instruction**:
```markdown
## Date and Time Handling
- Always use `event_date` column for date-based queries
- Default to **last 30 days** when no time period is specified
- Use `CURRENT_DATE()` for "today" and `DATE_SUB(CURRENT_DATE(), 30)` for "last 30 days"

## Metric Calculations
When calculating **revenue metrics**:
1. Use `total_revenue` column (already includes tax)
2. Round all monetary values to 2 decimal places
3. Filter out cancelled orders using `status != 'cancelled'`

## Clarification Questions
When users ask about performance but don't specify time range or product category, ask:
> "To analyze performance, please specify: (1) time period (e.g., last month, Q1 2024), and (2) product category you want to analyze."
```

### 8. Quality Assurance Layer (New 2026)

This section describes the three-priority quality assurance system that ensures generated configurations are production-ready.

#### 8.1 Domain Knowledge Extractor (Priority 3)

**Class**: `DomainKnowledgeExtractor`
**Module**: `genie/extractor/domain_extractor.py`

**Purpose**: Extract structured domain knowledge from requirements documents to provide explicit context to the LLM.

**Data Models**:
```python
@dataclass
class TableRelationship:
    left_table: str
    right_table: str
    relationship_type: str  # one-to-one, one-to-many, many-to-one, many-to-many
    join_column_left: Optional[str]
    join_column_right: Optional[str]
    description: Optional[str]

@dataclass
class BusinessMetric:
    name: str
    formula: str
    description: Optional[str]
    sql_expression: Optional[str]
    type: str  # metric, dimension, filter

@dataclass
class CommonFilter:
    name: str
    condition: str
    description: Optional[str]
    examples: List[str]

@dataclass
class DomainKnowledge:
    table_relationships: List[TableRelationship]
    business_metrics: List[BusinessMetric]
    common_filters: List[CommonFilter]
    table_descriptions: Dict[str, str]
    business_terms: Dict[str, str]
    sample_queries: List[Dict[str, str]]
```

**Extraction Patterns**:
- **Table Relationships**: `customers (1) -> orders (N)`, `orders N:1 products`, SQL JOIN clauses
- **Business Metrics**: `ARPU = revenue / customers`, `Revenue: SUM(amount)`, KPI sections
- **Common Filters**: `status != 'cancelled'`, `event_date >= DATE_SUB(CURRENT_DATE(), 30)`
- **Business Terms**: Glossary sections, `**ARPU**: Average Revenue Per User`
- **Sample Queries**: SQL code blocks with associated questions

**Output**: Structured context injected into LLM prompt
```markdown
## Extracted Table Relationships
- **transactions** (many-to-one) **customers**
  - Join: `customer_id` = `customer_id`
  - Each transaction belongs to one customer

## Key Business Metrics
- **ARPU**
  - Formula: `revenue / customers`
  - Average Revenue Per User

## Standard Filters
- **status**: `status != 'cancelled'`
  - Filter out cancelled transactions
```

#### 8.2 SQL Validator (Priority 2)

**Class**: `SQLValidator`
**Module**: `genie/validation/sql_validator.py`

**Purpose**: Comprehensive SQL syntax, table/column validation, and quality checking.

**Data Models**:
```python
@dataclass
class ValidationIssue:
    severity: str  # critical, high, medium, low, info
    category: str  # syntax, table, column, join, quality
    message: str
    suggestion: Optional[str]
    location: Optional[str]

@dataclass
class SQLValidationReport:
    is_valid: bool
    tables_referenced: Set[str]
    columns_referenced: Set[str]
    has_explicit_joins: bool
    issues: List[ValidationIssue]
```

**Validation Checks**:
1. **Syntax Validation**: Uses `sqlparse` to check SQL syntax
2. **Table References**: Verifies all tables exist in available tables list
3. **Join Patterns**: Checks for explicit JOIN conditions
4. **Quality Checks**:
   - SELECT * usage (should be avoided)
   - Hard-coded dates (should use CURRENT_DATE, DATE_SUB)
   - Aggregate without GROUP BY
   - Missing GROUP BY columns
   - Unsafe division (should use try_divide or NULLIF)

**Scoring**:
```
Score = 100 - (errors Ã— 10) - (warnings Ã— 2)
```

**Integration**: Validates all SQL in:
- `example_sql_queries`
- `sql_expressions`
- `benchmark_questions` (if they include SQL)

#### 8.3 Instruction Quality Scorer (Priority 2)

**Class**: `InstructionQualityScorer`
**Module**: `genie/validation/instruction_scorer.py`

**Purpose**: Score instruction quality across 3 dimensions to ensure clear, specific, well-structured guidance.

**Data Models**:
```python
@dataclass
class InstructionScore:
    specificity_score: float  # 0-40 points
    structure_score: float    # 0-30 points
    clarity_score: float      # 0-30 points
    total_score: float        # 0-100
    issues: List[str]
    suggestions: List[str]

@dataclass
class ConfigInstructionQualityReport:
    average_score: float
    total_instructions: int
    high_quality_count: int    # Score >= 80
    medium_quality_count: int  # 60 <= Score < 80
    low_quality_count: int     # Score < 60
    instruction_scores: List[InstructionScore]
```

**Scoring Dimensions**:

1. **Specificity (40 points)**:
   - Column names (+5 pts each, max 10)
   - Table names (+5 pts each, max 10)
   - SQL keywords (+2 pts each, max 10)
   - Concrete examples (+5 pts each, max 10)

2. **Structure (30 points)**:
   - Markdown headers (+10 pts)
   - Bullet/numbered lists (+10 pts)
   - Code blocks/inline code (+5 pts)
   - Bold emphasis (+5 pts)

3. **Clarity (30 points)**:
   - No vague terms (-5 pts each): "appropriate", "relevant", "properly", "good"
   - Actionable language (+10 pts): imperative verbs
   - Logical flow (+10 pts): sequential organization
   - Clear examples (+10 pts)

**Grade Assignment**:
- A: 90-100 (Excellent)
- B: 80-89 (Good)
- C: 70-79 (Acceptable)
- D: 60-69 (Needs improvement)
- F: 0-59 (Inadequate)

**Priority 1 Requirement**: Instructions marked as `priority: 1` must score â‰¥80.

#### 8.4 Benchmark SQL Generator (New 2026)

**Module**: `genie/utils/benchmark_sql_generator.py`
**Prompt Template**: `genie/prompt/templates/benchmark_sql_prompt.md`

**Purpose**: Generate SQL queries for benchmark questions using a two-pass approach that scales to 100+ benchmarks without token limit issues.

**Problem Solved**:
- Original single-pass approach generated incomplete SQL for large benchmark sets (27+ questions)
- Token budget exhaustion caused SQL truncation mid-generation
- LLM-generated benchmark SQL was discarded during extraction merge step (wasted tokens)

**Two-Pass Architecture**:

```
Pass 1 - Main Config Generation:
  â€¢ LLM generates tables, joins, instructions, example SQL
  â€¢ Benchmark questions extracted from requirements (regex)
  â€¢ Benchmarks have expected_sql: null (no SQL generated yet)
  â€¢ Token savings: ~25% reduction vs single-pass

Pass 2 - Focused Benchmark SQL Generation:
  â€¢ Filter benchmarks where expected_sql is None
  â€¢ Build focused prompt: table schemas + join specs + questions only
  â€¢ Call LLM in batches (default: 10 questions per call)
  â€¢ Parse and validate SQL responses
  â€¢ Update configuration with generated SQL
```

**Data Models**:
```python
class BenchmarkSQL(BaseModel):
    """Single benchmark SQL result from LLM."""
    question: str
    sql: str  # Complete SQL query ending with semicolon
    reasoning: Optional[str]

class BenchmarkSQLResponse(BaseModel):
    """Response from LLM for benchmark SQL generation."""
    benchmark_sqls: List[BenchmarkSQL]
    reasoning: Optional[str]
```

**Key Functions**:
```python
def generate_benchmark_sql_for_config(
    config: Dict[str, Any],
    llm_client: DatabricksLLMClient,
    max_tokens: int = 4000,
    temperature: float = 0.1,
    batch_size: int = 10,
    verbose: bool = False
) -> Dict[str, Any]:
    """Main orchestration function for two-pass approach."""

def build_benchmark_sql_prompt(
    tables: List[Dict],
    join_specs: List[Dict],
    benchmark_questions: List[Dict]
) -> str:
    """Build focused prompt for SQL generation only."""

def parse_benchmark_sql_response(
    response: BenchmarkSQLResponse
) -> List[Dict[str, Any]]:
    """Parse LLM response, validate completeness."""

def _batch_benchmarks(
    benchmarks: List[Dict],
    batch_size: int
) -> Iterator[List[Dict]]:
    """Split benchmarks into batches for processing."""
```

**Batching Strategy**:
- Default batch size: 10 questions per LLM call
- 27 benchmarks = 3 LLM calls (10 + 10 + 7)
- Configurable via `--benchmark-batch-size` CLI flag
- Each batch is independent (no dependencies between batches)

**CLI Usage**:
```bash
# Default: two-pass with batch size 10
genie.py generate --requirements data/requirements.md

# Custom batch size
genie.py generate --requirements data/requirements.md \
  --benchmark-batch-size 5

# Skip benchmark SQL generation (testing only)
genie.py generate --requirements data/requirements.md \
  --skip-benchmark-sql
```

**Performance Characteristics**:
- **Token savings in Pass 1**: ~25% reduction (no benchmark SQL)
- **Additional API calls**: +1 call per 10 benchmarks
- **For 27 benchmarks**: 1 main call + 3 batch calls = 4 total calls
- **Cost increase**: ~40% more API calls (necessary for correctness)
- **Time increase**: +15-30 seconds per generation
- **Scalability**: Supports unlimited benchmarks (tested with 100+)

**Benefits**:
- âœ… Scales to 100+ benchmarks without token limit errors
- âœ… Complete, correct SQL (no truncation or incomplete queries)
- âœ… Better SQL quality (focused prompts, no CTE reuse between unrelated questions)
- âœ… Cost-effective (only generates SQL for FAQ questions, not sample queries)
- âœ… Backwards compatible (sample queries with SQL in requirements work as-is)

**SQL Quality Validation**:
- Every SQL query must end with semicolon (auto-fixed if missing)
- Empty SQL raises validation error
- Question text must match exactly
- All questions from batch must be present in response

**Error Handling**:
- LLM failures raise `RuntimeError` with batch number
- Per-batch error handling (one failed batch doesn't affect others)
- Graceful handling of missing questions in response
- Verbose mode provides detailed progress tracking

**Test Coverage**:
- 16 unit tests (100% passing)
- Batching logic: 4 tests
- Prompt building: 3 tests
- Response parsing: 5 tests
- Integration tests: 4 tests
- End-to-end test in `test_generation.py`

#### 8.5 Configuration Review Agent (Priority 3)

**Class**: `ConfigReviewAgent`
**Module**: `genie/pipeline/reviewer.py`

**Purpose**: Comprehensive 4-dimension quality assessment of generated configurations before deployment.

**Data Models**:
```python
@dataclass
class ReviewIssue:
    severity: str  # critical, high, medium, low, info
    category: str  # sql, instructions, joins, coverage, structure
    message: str
    suggestion: Optional[str]
    affected_item: Optional[str]

@dataclass
class ConfigReviewReport:
    config_name: str
    overall_score: float  # 0-100
    passed: bool

    # Component scores
    sql_validation_score: float       # 35% weight
    instruction_quality_score: float  # 25% weight
    join_completeness_score: float    # 20% weight
    coverage_score: float             # 20% weight

    # Metrics
    total_sql_queries: int
    valid_sql_queries: int
    total_instructions: int
    high_quality_instructions: int
    documented_joins: int
    total_joins: int  # Expected = N-1 for N tables

    issues: List[ReviewIssue]
```

**Review Dimensions**:

1. **SQL Validation Score (35%)**:
   - Uses `SQLValidator` for all queries
   - Score = 100 - (errors Ã— 10) - (warnings Ã— 2)
   - Threshold: `min_sql_score` (default 70.0)

2. **Instruction Quality Score (25%)**:
   - Uses `InstructionQualityScorer`
   - Average across all instructions
   - Threshold: `min_instruction_score` (default 70.0)
   - Priority 1 instructions must score â‰¥80

3. **Join Completeness Score (20%)**:
   - Coverage = documented_joins / expected_joins
   - Expected joins = N-1 (minimum spanning tree for N tables)
   - Score = min(coverage Ã— 100, 100)
   - Critical if no joins for multiple tables

4. **Coverage Score (20%)**:
   - Example queries per table (aim: 2-3 per table)
   - Benchmark questions (aim: 10-20)
   - SQL expressions (metrics/dimensions/filters)
   - Score based on thresholds

**Overall Scoring**:
```
Overall = SQLÃ—0.35 + InstructionsÃ—0.25 + JoinsÃ—0.20 + CoverageÃ—0.20
```

**Pass/Fail Logic**:
- Critical issues â†’ Fail
- Overall score < 60 â†’ Fail
- Otherwise â†’ Pass

**Output Report**:
```
Configuration Review Report: Fashion Retail Analytics
============================================================
Overall Status: âœ… PASSED
Overall Score: 78.5/100

Component Scores:
  - SQL Validation: 85.0/100
  - Instruction Quality: 72.0/100
  - Join Completeness: 100.0/100
  - Coverage: 65.0/100

Issues Found:
  - Critical: 0
  - High: 1
  - Medium: 3
  - Low: 2
```

**Benefits**:
- **Better Organization**: Section headings group related instructions
- **Enhanced Readability**: Lists and formatting make instructions scannable
- **Clear Emphasis**: Bold text highlights critical terms
- **Code Clarity**: Inline code distinguishes column/table names from prose
- **Easier Maintenance**: Structured format is easier to update
- **Professional Appearance**: Consistent formatting across configurations

**Implementation**:
- Template file (`guide_prompt_with_reasoning.md`) includes markdown formatting guidance
- LLM automatically generates markdown-formatted instructions
- No manual formatting required from users

### 8. Output Layer

**Format**: JSON file with validated configuration

**Structure**:
```json
{
  "genie_space_config": {
    "space_name": "Fashion Retail Analytics",
    "description": "Natural language querying...",
    "purpose": "Enable business users...",
    "tables": [...],
    "instructions": [...],  // Now with markdown formatting
    "example_sql_queries": [...],
    "sql_expressions": [...],
    "benchmark_questions": [...]
  },
  "reasoning": "The configuration focuses on...",
  "confidence_score": 0.95
}
```

## Storage Abstraction Layer

**Purpose**: Enable multiple storage backends for file storage and session persistence through abstract base classes.

**Architecture**: The backend uses abstract base classes to decouple storage implementation from business logic, allowing easy extension to cloud storage (S3, Azure Blob) and different databases (PostgreSQL, Redis).

### File Storage Hierarchy

```
FileStorageBase (ABC)                    # Abstract interface
â”œâ”€â”€ LocalFileStorageService              # Local filesystem (default)
â””â”€â”€ [Future Extensions]
    â”œâ”€â”€ S3FileStorageService             # AWS S3 storage
    â”œâ”€â”€ AzureBlobStorageService          # Azure Blob storage
    â””â”€â”€ VolumeFileStorageService         # Unity Catalog Volumes
```

**Interface** (`backend/services/file_storage_base.py`):
- **Abstract Methods** (must implement):
  - `save_uploads(files, session_id)` â†’ Save uploaded files (async)
  - `get_session_dir(session_id)` â†’ Get session storage path
  - `create_session_dir(session_id)` â†’ Create session directory
  - `__init__(volume_path, **kwargs)` â†’ Initialize storage backend

- **Helper Methods** (can override):
  - `validate_session_id(session_id)` â†’ Validate session ID format
  - `cleanup_session(session_id)` â†’ Clean up session storage

**Current Implementation**:
- `LocalFileStorageService`: Stores files in `storage/uploads/{session_id}/`
- Used by: File upload endpoints, job tasks

### Session Storage Hierarchy

```
SessionStoreBase (ABC)                   # Abstract interface
â”œâ”€â”€ SQLiteSessionStore                   # SQLite database (default)
â””â”€â”€ [Future Extensions]
    â”œâ”€â”€ PostgreSQLSessionStore           # PostgreSQL database
    â”œâ”€â”€ RedisSessionStore                # Redis in-memory storage
    â””â”€â”€ InMemorySessionStore             # Testing/development
```

**Interface** (`backend/services/session_store_base.py`):
- **Abstract Methods** (must implement):
  - Session CRUD (6 methods):
    - `create_session(user_id, name)` â†’ Create new session
    - `get_session_with_stats(session_id)` â†’ Get session with job count
    - `list_sessions(user_id, limit, offset)` â†’ List sessions with pagination
    - `update_session_name(session_id, name)` â†’ Update session name
    - `update_session_activity(session_id)` â†’ Update timestamp
    - `delete_session(session_id)` â†’ Delete session and jobs (cascade)

  - Job CRUD (4 methods):
    - `save_job(job)` â†’ Save new job record
    - `get_job(job_id)` â†’ Retrieve job by ID
    - `update_job(job)` â†’ Update job status/result
    - `get_jobs_for_session(session_id)` â†’ Get all session jobs

  - Initialization (1 method):
    - `__init__(**kwargs)` â†’ Initialize storage backend

- **Hook Methods** (can override):
  - `setup_schema()` â†’ Create database schema
  - `migrate_schema()` â†’ Run schema migrations
  - `health_check()` â†’ Check storage health
  - `close()` â†’ Close connections

**Current Implementation**:
- `SQLiteSessionStore`: Stores sessions and jobs in `storage/sessions.db`
- Schema:
  - `genie_sessions`: session_id, user_id, name, created_at, updated_at
  - `genie_jobs`: job_id, session_id, type, status, inputs, result, error, created_at, completed_at, progress
- Used by: JobManager, session endpoints, job status tracking

### Job Model

**Defined in**: `backend/services/session_store_base.py`

```python
class Job(BaseModel):
    job_id: str                    # UUID
    session_id: str                # Parent session
    type: str                      # parse, generate, validate, deploy
    status: str                    # pending, running, completed, failed
    inputs: dict                   # Job input parameters
    result: Optional[dict]         # Job output (on completion)
    error: Optional[str]           # Error message (on failure)
    created_at: Optional[datetime] # Creation timestamp
    completed_at: Optional[datetime]  # Completion timestamp
    progress: Optional[dict]       # Progress tracking data
```

### Usage Examples

**File Storage**:
```python
from backend.services.file_storage import LocalFileStorageService

# Initialize
storage = LocalFileStorageService()

# Save files
paths = await storage.save_uploads(files, session_id)

# Get session directory
session_dir = storage.get_session_dir(session_id)
```

**Session Storage**:
```python
from backend.services.session_store import SQLiteSessionStore

# Initialize
store = SQLiteSessionStore()

# Create session
session_id = store.create_session(user_id="user-123", name="My Session")

# Save job
job = Job(job_id=str(uuid.uuid4()), session_id=session_id,
          type="generate", status="pending", inputs={"config": "data"})
store.save_job(job)

# Get job
job = store.get_job(job_id)

# Update job
job.status = "completed"
job.result = {"output": "data"}
store.update_job(job)
```

### Dependency Injection

**JobManager** (`backend/services/job_manager.py`):
- Accepts `SessionStoreBase` in constructor (not concrete implementation)
- Enables testing with mock stores
- Supports runtime backend selection

```python
from backend.services.job_manager import JobManager
from backend.services.session_store import SQLiteSessionStore

store = SQLiteSessionStore()
manager = JobManager(session_store=store)
```

### Extension Pattern

To add a new storage backend:

1. **Create new implementation**:
   ```python
   from backend.services.file_storage_base import FileStorageBase

   class S3FileStorageService(FileStorageBase):
       def __init__(self, bucket: str, **kwargs):
           self.bucket = bucket
           self.s3 = boto3.client('s3')

       async def save_uploads(self, files, session_id):
           # Implement S3 upload logic
           ...
   ```

2. **Add factory function** (in `backend/main.py`):
   ```python
   def create_file_storage():
       backend = os.getenv("FILE_STORAGE_BACKEND", "local")
       if backend == "s3":
           return S3FileStorageService(bucket=os.getenv("S3_BUCKET"))
       return LocalFileStorageService()

   file_storage = create_file_storage()
   ```

3. **Configure via environment variables**:
   ```bash
   FILE_STORAGE_BACKEND=s3
   S3_BUCKET=my-genie-bucket
   ```

## Data Flow Diagram

### Complete End-to-End Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER ENTRY POINTS                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. genie.py create (Automated - Full Pipeline)                 â”‚
â”‚  2. genie.py parse (Document Parsing)                           â”‚
â”‚  3. genie.py generate (Config Generation)                       â”‚
â”‚  4. genie.py validate (Table Validation)                        â”‚
â”‚  5. genie.py deploy (Space Deployment)                          â”‚
â”‚  6. examples/create_genie_space_example.py (Python API)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 1: CONFIG GENERATION                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

genie.py (CLI Entry Point)
    â”‚
    â”œâ”€â”€â”€ Load environment (.env file)
    â”œâ”€â”€â”€ Parse command-line arguments
    â”‚    â€¢ Command: parse, create, generate, validate, deploy
    â”‚    â€¢ --model, --endpoint
    â”‚    â€¢ --requirements, --config, --output
    â”‚    â€¢ --max-tokens, --temperature
    â”‚    â€¢ --max-concurrent (for parse)
    â”‚
    â””â”€â”€â”€ Route to appropriate pipeline function
            â”‚
            â–¼

STEP 1: ðŸ†• Domain Knowledge Extraction (P3)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DomainKnowledgeExtractor.extract_from_file()
    â”œâ”€â”€â”€ Extract table relationships (1:1, 1:N, N:1, N:M)
    â”œâ”€â”€â”€ Extract business metrics (formulas, KPIs)
    â”œâ”€â”€â”€ Extract common filters
    â”œâ”€â”€â”€ Extract business terminology
    â””â”€â”€â”€ Return DomainKnowledge object
            â”‚
            â–¼

STEP 2: ðŸ†• Enhanced Prompt Building (P1 + P3)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PromptBuilder.build_prompt_with_reasoning(domain_knowledge)
    â”‚
    â”œâ”€â”€â”€ Read genie/prompt/templates/curate_effective_genie.md
    â”‚        (Best practices, principles, guidelines)
    â”‚
    â”œâ”€â”€â”€ Read genie/prompt/templates/genie_api.md
    â”‚        (API schema, output format, examples)
    â”‚
    â”œâ”€â”€â”€ Read sample/inputs/demo_requirements.md
    â”‚        (Business requirements, tables, questions)
    â”‚
    â”œâ”€â”€â”€ ðŸ†• Inject extracted domain knowledge as structured context
    â”‚
    â””â”€â”€â”€ Construct enhanced prompt with:
            â€¢ ðŸ†• SQL Quality Criteria (6-point checklist)
            â€¢ ðŸ†• Few-Shot Examples (high vs low quality)
            â€¢ ðŸ†• Instruction Guidelines (5 principles)
            â€¢ ðŸ†• Join Specification Requirements
            â€¢ Context section (best practices)
            â€¢ Output format section (schema)
            â€¢ Input section (enhanced requirements)
            â”‚
            â–¼

STEP 3: LLM Generation
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

DatabricksFoundationModelClient.generate_genie_config()
    â”‚
    â”œâ”€â”€â”€ Format request payload
    â”‚       {
    â”‚         "messages": [{"role": "user", "content": prompt}],
    â”‚         "max_tokens": 16000,  # Higher for reasoning models
    â”‚         "temperature": 0.1
    â”‚       }
    â”‚
    â”œâ”€â”€â”€ POST to serving endpoint
    â”‚       https://{host}/serving-endpoints/{model}/invocations
    â”‚       Models: databricks-gpt-5-2, llama-3-1-70b, etc.
    â”‚
    â”œâ”€â”€â”€ Receive response
    â”‚       {
    â”‚         "choices": [{
    â”‚           "message": {
    â”‚             "content": "{ genie_space_config: {...}, reasoning: ..., confidence_score: ... }"
    â”‚           }
    â”‚         }]
    â”‚       }
    â”‚
    â””â”€â”€â”€ Extract and clean JSON content
            â€¢ Find JSON boundaries { ... }
            â€¢ Remove markdown code blocks if present
            â”‚
            â–¼

Pydantic Validation (genie/models.py)
    â”‚
    â”œâ”€â”€â”€ Parse JSON string
    â”œâ”€â”€â”€ Validate against LLMResponse schema
    â”‚    â”œâ”€â”€â”€ genie_space_config: GenieSpaceConfig
    â”‚    â”‚    â”œâ”€â”€â”€ space_name, description, purpose
    â”‚    â”‚    â”œâ”€â”€â”€ tables: List[GenieSpaceTable]
    â”‚    â”‚    â”œâ”€â”€â”€ instructions: List[GenieSpaceInstruction]
    â”‚    â”‚    â”œâ”€â”€â”€ example_sql_queries: List[GenieSpaceExampleSQL]
    â”‚    â”‚    â”œâ”€â”€â”€ sql_snippets: Optional[GenieSpaceSQLSnippets]
    â”‚    â”‚    â”‚    â”œâ”€â”€â”€ filters: List[GenieSpaceSQLFilter]
    â”‚    â”‚    â”‚    â”œâ”€â”€â”€ expressions: List[GenieSpaceSQLExpression] (with instruction support)
    â”‚    â”‚    â”‚    â””â”€â”€â”€ measures: List[GenieSpaceSQLMeasure] (with instruction support)
    â”‚    â”‚    â””â”€â”€â”€ benchmark_questions: List[GenieSpaceBenchmark]
    â”‚    â”œâ”€â”€â”€ reasoning: Optional[str]
    â”‚    â””â”€â”€â”€ confidence_score: Optional[float]
    â”‚
    â”œâ”€â”€â”€ Type check all fields
    â”œâ”€â”€â”€ Verify required fields
    â”œâ”€â”€â”€ Apply field constraints
    â”‚
    â””â”€â”€â”€ Create validated LLMResponse object
            â”‚
            â–¼

STEP 4: Benchmark Extraction & SQL Generation (Two-Pass, 2026)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Pass 1 - BenchmarkExtractor.extract_all_benchmarks()
    â”œâ”€â”€â”€ Extract FAQ questions (100% coverage, expected_sql: null)
    â”œâ”€â”€â”€ Extract sample queries from requirements (with SQL)
    â””â”€â”€â”€ Merge into configuration
            â”‚
            â–¼

Pass 2 - BenchmarkSQLGenerator.generate_benchmark_sql_for_config()
    â”œâ”€â”€â”€ Filter benchmarks where expected_sql is None
    â”œâ”€â”€â”€ Build focused prompt (tables + join specs + questions)
    â”œâ”€â”€â”€ Call LLM in batches (default: 10 questions per batch)
    â”‚    â”œâ”€â”€â”€ Batch 1: Questions 1-10  â†’ SQL queries
    â”‚    â”œâ”€â”€â”€ Batch 2: Questions 11-20 â†’ SQL queries
    â”‚    â””â”€â”€â”€ Batch N: Remaining       â†’ SQL queries
    â”œâ”€â”€â”€ Parse and validate SQL responses
    â”‚    â”œâ”€â”€â”€ Ensure SQL completeness (ends with semicolon)
    â”‚    â””â”€â”€â”€ Handle errors gracefully
    â””â”€â”€â”€ Update configuration with generated SQL
            â”‚
            â–¼

Benefits:
  â€¢ Scales to 100+ benchmarks without token limit issues
  â€¢ Better SQL quality (focused prompts, no CTE reuse)
  â€¢ Cost-effective (only generates SQL for FAQ questions)
  â€¢ Backwards compatible (sample queries with SQL work as-is)
            â”‚
            â–¼

STEP 5: ðŸ†• SQL & Instruction Validation (P2)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SQLValidator.validate_config_sql()
    â”œâ”€â”€â”€ Validate example SQL queries
    â”œâ”€â”€â”€ Validate SQL expressions
    â”œâ”€â”€â”€ Check: syntax, tables, joins, quality patterns
    â””â”€â”€â”€ Generate SQL validation report

InstructionQualityScorer.score_config_instructions()
    â”œâ”€â”€â”€ Score each instruction (0-100)
    â”œâ”€â”€â”€ Check: specificity, structure, clarity
    â””â”€â”€â”€ Generate instruction quality report
            â”‚
            â–¼

STEP 6: ðŸ†• Comprehensive Config Review (P3)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ConfigReviewAgent.review_config()
    â”œâ”€â”€â”€ SQL Validation Score (35%)
    â”œâ”€â”€â”€ Instruction Quality Score (25%)
    â”œâ”€â”€â”€ Join Completeness Score (20%)
    â”œâ”€â”€â”€ Coverage Score (20%)
    â”œâ”€â”€â”€ Overall Score = weighted sum
    â””â”€â”€â”€ Generate review report with pass/fail + issues
            â”‚
            â–¼

STEP 7: Save Configuration & Reports
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â”œâ”€â”€â”€ Convert to JSON (model.model_dump())
    â”œâ”€â”€â”€ Save output/genie_space_config.json
    â”œâ”€â”€â”€ Save output/validation_report.json (if requested)
    â””â”€â”€â”€ Save output/review_report.json (if requested)
            â”‚
            â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          PHASE 2: TABLE & COLUMN VALIDATION (RECOMMENDED)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

genie.py validate (or src.pipeline.validator)
    â”‚
    â”œâ”€â”€â”€ Load configuration from JSON file
    â”‚       output/genie_space_config.json
    â”‚
    â”œâ”€â”€â”€ Initialize TableValidator
    â”‚       â€¢ Load credentials from .env
    â”‚       â€¢ Set up Unity Catalog connection
    â”‚
    â””â”€â”€â”€ Validate configuration
            â”‚
            â–¼

TableValidator.validate_config()
    â”‚
    â”œâ”€â”€â”€ Parse configuration
    â”‚    â€¢ Extract table definitions
    â”‚    â€¢ Extract SQL expressions
    â”‚    â€¢ Extract example queries
    â”‚
    â”œâ”€â”€â”€ Validate tables
    â”‚    For each table:
    â”‚       GET /api/2.1/unity-catalog/tables/{catalog}.{schema}.{table}
    â”‚       or fallback: DESCRIBE TABLE {catalog}.{schema}.{table}
    â”‚       â””â”€â”€â”€ Cache schema for performance
    â”‚
    â”œâ”€â”€â”€ Extract and validate columns
    â”‚    â€¢ Parse SQL expressions for column references
    â”‚    â€¢ Build alias map (t â†’ transactions, a â†’ articles, etc.)
    â”‚    â€¢ Verify columns exist in table schemas
    â”‚    â€¢ Check case-insensitively
    â”‚
    â””â”€â”€â”€ Generate ValidationReport
            â€¢ tables_valid / tables_invalid
            â€¢ columns_valid / columns_invalid
            â€¢ issues (errors, warnings, info)
            â”‚
            â–¼

Review Validation Report
    â”‚
    â”œâ”€â”€â”€ If errors found:
    â”‚       â€¢ Fix table/column references
    â”‚       â€¢ Update configuration
    â”‚       â€¢ Re-run validation
    â”‚
    â””â”€â”€â”€ If validation passes:
            â”‚
            â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             PHASE 3: GENIE SPACE CREATION                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

genie.py deploy (or src.pipeline.deployer)
    â”‚
    â”œâ”€â”€â”€ Load configuration from JSON file
    â”‚       output/genie_space_config.json
    â”‚
    â”œâ”€â”€â”€ Initialize GenieSpaceClient
    â”‚       â€¢ Load credentials from .env
    â”‚       â€¢ Set up API connection
    â”‚
    â””â”€â”€â”€ Create space
            â”‚
            â–¼

GenieSpaceClient.create_space()
    â”‚
    â”œâ”€â”€â”€ Validate configuration
    â”‚    â€¢ Check warehouse_id is set
    â”‚    â€¢ Extract space_name, description
    â”‚
    â”œâ”€â”€â”€ Transform configuration
    â”‚       config_transformer.transform_to_serialized_space()
    â”‚       â”‚
    â”‚       â”œâ”€â”€â”€ Convert text fields to arrays of strings
    â”‚       â”œâ”€â”€â”€ Nest instructions into sub-sections:
    â”‚       â”‚    â€¢ text_instructions
    â”‚       â”‚    â€¢ join_specs
    â”‚       â”‚    â€¢ example_question_sqls
    â”‚       â”œâ”€â”€â”€ Generate unique IDs for all items
    â”‚       â”œâ”€â”€â”€ Sort tables by identifier
    â”‚       â””â”€â”€â”€ Format joins with relationship types
    â”‚
    â”œâ”€â”€â”€ Build API payload
    â”‚       {
    â”‚         "warehouse_id": "...",
    â”‚         "title": "...",
    â”‚         "description": "...",
    â”‚         "serialized_space": "{ JSON string }",
    â”‚         "parent_path": "/Workspace/..." (optional)
    â”‚       }
    â”‚
    â”œâ”€â”€â”€ POST to Genie Spaces API
    â”‚       POST /api/2.0/genie/spaces
    â”‚       Headers: Authorization: Bearer {token}
    â”‚
    â””â”€â”€â”€ Receive response
            {
              "space_id": "01f0f7a0f1571de6bfd79fa6...",
              "space_name": "...",
              "warehouse_id": "...",
              ...
            }
            â”‚
            â–¼

Save Creation Result
    â”‚
    â”œâ”€â”€â”€ Extract space_id from response
    â”œâ”€â”€â”€ Generate space_url (UI URL)
    â”‚       https://{host}/genie/rooms/{space_id}?o={org_id}
    â”‚       Note: API uses /genie/spaces/, UI uses /genie/rooms/
    â”‚
    â””â”€â”€â”€ Write to output/genie_space_result.json
            {
              "space_id": "...",
              "space_url": "...",
              "response": { full API response }
            }
            â”‚
            â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GENIE SPACE READY TO USE                      â”‚
â”‚                                                                  â”‚
â”‚  â€¢ Accessible via Databricks UI                                  â”‚
â”‚  â€¢ Ready for natural language queries                            â”‚
â”‚  â€¢ Can be updated via API                                        â”‚
â”‚  â€¢ Can be managed via GenieSpaceClient                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Alternative Workflows

#### Workflow A: Automated End-to-End (Unified CLI)

```
genie.py create --requirements data/requirements.md
    â”‚
    â”œâ”€â”€â”€ Step 1: Generate config (src.pipeline.generate_config)
    â”‚       â””â”€â”€â”€ Output: genie_space_config.json
    â”‚
    â”œâ”€â”€â”€ Step 2: Validate (src.pipeline.validate_config)
    â”‚       â””â”€â”€â”€ Interactive catalog/schema replacement if needed
    â”‚
    â””â”€â”€â”€ Step 3: Deploy (src.pipeline.deploy_space)
            â””â”€â”€â”€ Output: genie_space_result.json + Space URL
```

#### Workflow B: Python API Usage

```
examples/create_genie_space_example.py
    â”‚
    â”œâ”€â”€â”€ Load configuration from file
    â”œâ”€â”€â”€ create_genie_space_from_file()
    â”‚       â””â”€â”€â”€ GenieSpaceClient methods
    â”‚
    â””â”€â”€â”€ Display space_id and space_url
```

#### Workflow C: Iterative Management

```
1. Create space
   â””â”€â”€â”€ GenieSpaceClient.create_space()

2. List all spaces (with pagination)
   â””â”€â”€â”€ GenieSpaceClient.list_spaces()

3. Get space details (with full config)
   â””â”€â”€â”€ GenieSpaceClient.get_space(include_serialized_space=True)

4. Update space (partial or full)
   â””â”€â”€â”€ GenieSpaceClient.update_space()

5. Move to trash (recoverable)
   â””â”€â”€â”€ GenieSpaceClient.trash_space()
```

## Module Dependency Graph

```
genie.py (Unified CLI)
    â”‚
    â”œâ”€â”€ Command: parse
    â”‚   â””â”€â”€ src.pipeline.parser
    â”‚       â”œâ”€â”€ parse_documents() / parse_documents_async()
    â”‚       â”œâ”€â”€ src.parsing.pdf_parser (PDFParser)
    â”‚       â”œâ”€â”€ src.parsing.markdown_parser (MarkdownParser)
    â”‚       â”œâ”€â”€ src.parsing.requirements_structurer
    â”‚       â”œâ”€â”€ src.parsing.llm_enricher (LLMEnricher)
    â”‚       â””â”€â”€ src.parsing.markdown_generator
    â”‚           â””â”€â”€ Uses: aiohttp, tqdm, pdfplumber
    â”‚
    â”œâ”€â”€ Command: generate
    â”‚   â””â”€â”€ src.pipeline.generator
    â”‚       â”œâ”€â”€ generate_config()
    â”‚       â”œâ”€â”€ src.prompt.prompt_builder (PromptBuilder)
    â”‚       â”œâ”€â”€ src.llm.databricks_llm (DatabricksFoundationModelClient)
    â”‚       â”œâ”€â”€ src.utils.benchmark_extractor (Pass 1: Extract questions)
    â”‚       â”œâ”€â”€ src.utils.benchmark_sql_generator (Pass 2: Generate SQL, NEW 2026)
    â”‚       â””â”€â”€ src.models (Pydantic models)
    â”‚           â””â”€â”€ Uses: pydantic, requests
    â”‚
    â”œâ”€â”€ Command: validate
    â”‚   â””â”€â”€ src.pipeline.validator
    â”‚       â”œâ”€â”€ validate_config()
    â”‚       â””â”€â”€ src.utils.table_validator (TableValidator)
    â”‚           â””â”€â”€ Uses: requests, Unity Catalog API
    â”‚
    â”œâ”€â”€ Command: deploy
    â”‚   â””â”€â”€ src.pipeline.deployer
    â”‚       â”œâ”€â”€ deploy_space()
    â”‚       â”œâ”€â”€ src.api.genie_space_client (GenieSpaceClient)
    â”‚       â””â”€â”€ src.utils.config_transformer
    â”‚
    â””â”€â”€ Command: create (combines all above)
        â”œâ”€â”€ generate_config()
        â”œâ”€â”€ validate_config()
        â””â”€â”€ deploy_space()

examples/create_genie_space_example.py (Usage Examples)
    â”‚
    â””â”€â”€ src.api.genie_space_client
            â”œâ”€â”€ create_genie_space_from_file()
            â”œâ”€â”€ GenieSpaceClient
            â”‚   â”œâ”€â”€ create_space()
            â”‚   â”œâ”€â”€ get_space()
            â”‚   â”œâ”€â”€ list_spaces()
            â”‚   â”œâ”€â”€ update_space()
            â”‚   â””â”€â”€ trash_space()
            â””â”€â”€ Uses: all client methods with examples

scripts/validate_setup.py (Setup Validation)
    â””â”€â”€ Validates: environment variables, credentials, connectivity

scripts/convert_requirements.py (Requirements Conversion)
    â””â”€â”€ src.parsing modules for document conversion

scripts/auto_deploy.py (Automated Deployment)
    â””â”€â”€ Full pipeline with automatic catalog/schema replacement

scripts/analyze_feedback.py (Feedback Analysis)
    â””â”€â”€ src.parsing.feedback_parser for quality assessment

scripts/export_feedback_csv.py (Feedback Export)
    â””â”€â”€ Export feedback data to CSV format
```

## Error Handling Flow

```
Try:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Read Input Files       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”œâ”€ FileNotFoundError â†’ "Input file missing"
              â”‚
              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Build Prompt           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”œâ”€ ValueError â†’ "Invalid document format"
              â”‚
              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Call LLM API           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”œâ”€ ConnectionError â†’ "Cannot reach endpoint"
              â”œâ”€ AuthenticationError â†’ "Invalid credentials"
              â”œâ”€ TimeoutError â†’ "Request timed out"
              â”‚
              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Parse Response         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”œâ”€ JSONDecodeError â†’ "Invalid JSON response"
              â”œâ”€ ValueError â†’ "No JSON found in response"
              â”‚
              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Validate with Pydantic â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”œâ”€ ValidationError â†’ "Schema mismatch"
              â”œâ”€ TypeError â†’ "Type error"
              â”‚
              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Save Output            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”œâ”€ PermissionError â†’ "Cannot write to output"
              â”‚
              â–¼
         Success!
```

## Configuration Options

### Runtime Configuration

```python
# Model selection
--endpoint my-endpoint      # Use custom endpoint
--model llama-3-1-70b       # Use foundation model

# Input/Output
--input-data path/to/req.md # Input requirements
--output path/to/output.json # Output location

# Generation parameters
--max-tokens 4000           # Max response tokens
--temperature 0.1           # Sampling temperature (0.0-1.0)
--no-reasoning              # Skip reasoning output

# Benchmark SQL generation (NEW 2026)
--benchmark-batch-size 10   # Batch size for SQL generation (default: 10)
--skip-benchmark-sql        # Skip benchmark SQL generation (testing only)

# Authentication
--databricks-host https://... # Databricks workspace URL
--databricks-token dapi...    # Personal access token
```

### Environment Variables

```bash
export DATABRICKS_HOST="https://workspace.databricks.com"
export DATABRICKS_TOKEN="dapi1234..."
```

## Performance Characteristics

| Metric | Typical Value | Notes |
|--------|---------------|-------|
| Prompt Length | 40-50 KB | Depends on input doc sizes |
| Request Time (Single-Pass) | 30-60 seconds | Model-dependent |
| Request Time (Two-Pass) | 45-90 seconds | +15-30s for benchmark SQL generation |
| Token Usage (Pass 1) | 3000-4000 | Main config generation (~25% savings vs old) |
| Token Usage (Pass 2) | 1000-2000 per batch | Benchmark SQL generation (10 questions/batch) |
| LLM API Calls (27 benchmarks) | 4 total | 1 main + 3 batches (10+10+7) |
| Output Size | 10-50 KB | JSON configuration |
| Memory Usage | < 100 MB | Lightweight |
| Concurrent Requests | 1 | Sequential by design |
| Scalability (Benchmarks) | 100+ supported | Two-pass approach prevents token limit errors |

## Security Considerations

1. **Credentials**: Never commit tokens to git
2. **Environment Variables**: Use for sensitive data
3. **Output**: Review before sharing (may contain schema info)
4. **API Rate Limits**: Respect Databricks quotas
5. **Data Privacy**: Input docs may contain sensitive info

## Scripts and Utilities

### 1. Unified CLI (`genie.py`)

**Purpose**: Single entry point for all Genie space operations

**Available Commands**:
- `parse` - Parse documents into structured requirements
- `create` - Full pipeline (generate â†’ validate â†’ deploy)
- `generate` - Generate configuration only
- `validate` - Validate tables and columns
- `deploy` - Deploy existing configuration

**Key Features**:
- Unified interface for all operations
- Built-in progress indicators
- Interactive catalog/schema replacement
- Automatic benchmark extraction
- Environment variable support
- Error handling with helpful messages

**Usage**:
```bash
# Parse documents
genie.py parse --input-dir docs/ --output data/requirements.md --max-concurrent 5

# Complete workflow (recommended)
genie.py create --requirements data/requirements.md

# Individual steps
genie.py generate --requirements data/requirements.md
genie.py validate --config output/genie_space_config.json
genie.py deploy --config output/genie_space_config.json
```

### 2. Setup Validation Script (`scripts/validate_setup.py`)

**Purpose**: Validate environment setup and connectivity

**Checks**:
- Environment variables
- Databricks credentials
- API connectivity
- Python dependencies

**Usage**:
```bash
python scripts/validate_setup.py
```

### 3. Auto-Deploy Script (`scripts/auto_deploy.py`)

**Purpose**: Automated deployment with catalog/schema replacement

**Features**:
- Full pipeline automation (generate â†’ validate â†’ deploy)
- Automatic catalog/schema replacement for all tables
- Non-interactive deployment for CI/CD workflows
- Custom warehouse and parent path support

**Usage**:
```bash
# Basic auto-deploy
.venv/bin/python scripts/auto_deploy.py

# With custom catalog/schema
.venv/bin/python scripts/auto_deploy.py \
  --requirements data/parsed.md \
  --catalog sandbox \
  --schema agent_poc

# With all options
.venv/bin/python scripts/auto_deploy.py \
  --requirements data/parsed.md \
  --output output/config.json \
  --catalog prod \
  --schema analytics \
  --warehouse-id your-warehouse-id
```

**Process**:
1. Generate configuration from requirements
2. Replace all catalog.schema references
3. Validate tables (non-interactive)
4. Deploy space
5. Output space URL and ID

### 4. Feedback Analysis Scripts (`scripts/analyze_feedback.py`, `scripts/export_feedback_csv.py`)

**Purpose**: Analyze Genie Space response quality and user feedback

**analyze_feedback.py**:
- Parses feedback markdown files
- Generates comprehensive analysis reports
- Success rate and failure pattern analysis
- Common error detection

**export_feedback_csv.py**:
- Exports feedback to CSV format
- Creates summary and detailed reports
- Excel/Google Sheets compatible

**Usage**:
```bash
# Analyze feedback
.venv/bin/python scripts/analyze_feedback.py feedback/results.md

# Export to CSV
.venv/bin/python scripts/export_feedback_csv.py feedback/results.md

# Outputs:
# - feedback/results_summary.csv (summary)
# - feedback/results_detailed.csv (detailed)
```

**Feedback Entry Structure**:
```python
@dataclass
class FeedbackEntry:
    question: str
    assessment: str  # "Good" or "Bad"
    score_reasons: List[str]
    model_output_type: str  # "SQL" or "text"
    model_output: str
    empty_result: bool
    failure_reasoning: str
    sql_differences: str
    ground_truth_sql: str
```

**Analysis Metrics**:
- Total questions evaluated
- Success rate (Good vs Bad assessments)
- Failure reason breakdown
- Empty result detection
- SQL comparison analysis

### 5. Genie Space Usage Examples (`examples/create_genie_space_example.py`)

**Purpose**: Demonstrate Python API usage patterns

**Examples Include**:
- `example_create_space_from_file()`: Create space from JSON file
- `example_create_space_programmatic()`: Create space with Python API
- `example_list_spaces()`: List all Genie spaces
- `example_list_spaces_paginated()`: List spaces with pagination
- `example_update_space()`: Update entire space configuration
- `example_update_space_partial()`: Update only specific fields
- `example_get_space_with_serialization()`: Get space with full config
- `example_trash_space()`: Move space to trash
- `example_create_space_with_parent_path()`: Create space in specific folder

**Usage**:
```python
from examples.create_genie_space_example import example_create_space_from_file

# Create space from configuration file
result = example_create_space_from_file()
print(f"Space URL: {result['space_url']}")
```

---

## Extension Points

To extend the system:

1. **Add new input sources**
   - Modify `PromptBuilder` to support additional docs
   - Add new sections to prompt template

2. **Support new LLM providers**
   - Subclass `DatabricksLLMClient`
   - Implement provider-specific request/response handling

3. **Add new output formats**
   - Create new Pydantic models
   - Add conversion methods

4. **Enhance validation**
   - Add custom validators to Pydantic models
   - Implement business rule checks

5. **Add post-processing**
   - Create pipeline after validation
   - Transform, enrich, or validate further

6. **Custom scripts**
   - Create new scripts in `scripts/` directory
   - Follow existing patterns for error handling and logging

## Testing Strategy

```
Unit Tests
â”œâ”€â”€ test_models.py
â”‚   â”œâ”€â”€ Test Pydantic validation
â”‚   â”œâ”€â”€ Test JSON serialization
â”‚   â””â”€â”€ Test edge cases
â”‚
â”œâ”€â”€ test_prompt_builder.py
â”‚   â”œâ”€â”€ Test file reading
â”‚   â”œâ”€â”€ Test prompt construction
â”‚   â””â”€â”€ Test template rendering
â”‚
â””â”€â”€ test_llm_client.py
    â”œâ”€â”€ Test request formatting
    â”œâ”€â”€ Test response parsing
    â””â”€â”€ Test error handling

Integration Tests
â”œâ”€â”€ test_end_to_end.py
â”‚   â”œâ”€â”€ Test full pipeline
â”‚   â”œâ”€â”€ Test with mock LLM
â”‚   â””â”€â”€ Test output validation
â”‚
â””â”€â”€ tests/
    â””â”€â”€ test_generation.py (current)
        â”œâ”€â”€ Test file structure
        â”œâ”€â”€ Test model validation
        â””â”€â”€ Test prompt building
```

## Monitoring and Debugging

### Logging Points

```python
# In genie.py / pipeline modules
log.info("Building prompt...")
log.info(f"Prompt length: {len(prompt)}")
log.info("Calling LLM...")
log.info("Configuration generated")
log.info(f"Saved to: {output_path}")

# In databricks_llm.py
log.debug(f"Request: {payload}")
log.debug(f"Response: {response}")
log.error(f"API error: {e}")

# In prompt_builder.py
log.debug(f"Read {len(content)} chars from {path}")
```

### Debug Mode

Add `--debug` flag to enable:
- Full request/response logging
- Intermediate prompt states
- Validation details
- Timing information

## Deployment Options

### Local Development
```bash
genie.py create --requirements data/requirements.md
```

### Automated Workflow
```bash
# Generate config and create space in one command
genie.py create \
  --requirements sample/inputs/demo_requirements.md \
  --model databricks-gpt-5-2 \
  --max-tokens 16000
```

### Scheduled Job
```bash
# Run as a Python task in Databricks Job
genie.py create \
  --requirements /dbfs/requirements.md \
  --model databricks-gpt-5-2 \
  --output /dbfs/output/config.json
```

### API Endpoint
Wrap in FastAPI or Flask for HTTP endpoint

### CI/CD Pipeline
Integrate into automated workflow

---

## Genie Space API Integration

After the LLM generates the Genie space configuration, you can use the Genie Space API to create or update actual Genie spaces in Databricks.

### Architecture Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CONFIGURATION GENERATION                        â”‚
â”‚  (genie.py generate â†’ LLM â†’ genie_space_config.json)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CONFIG TRANSFORMATION LAYER                        â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  config_transformer.py                                        â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚ transform_to_serialized_space()                         â”‚ â”‚ â”‚
â”‚  â”‚  â”‚                                                         â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ Input:  User-friendly config format                    â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ Output: Databricks serialized_space format             â”‚ â”‚ â”‚
â”‚  â”‚  â”‚                                                         â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ Transformations:                                        â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Convert strings to arrays of strings                 â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Nest instructions properly                           â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Generate unique IDs                                  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Sort tables by identifier                            â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Format joins with relationship types                 â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     GENIE SPACE API LAYER                            â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  GenieSpaceClient (genie_space_client.py)                    â”‚ â”‚
â”‚  â”‚                                                               â”‚ â”‚
â”‚  â”‚  Core Methods:                                                â”‚ â”‚
â”‚  â”‚  â€¢ create_space(config, parent_path=None)                    â”‚ â”‚
â”‚  â”‚    â†’ Create new Genie space with optional folder path        â”‚ â”‚
â”‚  â”‚  â€¢ get_space(space_id, include_serialized_space=False)       â”‚ â”‚
â”‚  â”‚    â†’ Fetch space (optionally with full config)               â”‚ â”‚
â”‚  â”‚  â€¢ list_spaces(page_size=None, page_token=None)              â”‚ â”‚
â”‚  â”‚    â†’ List all spaces with pagination support                 â”‚ â”‚
â”‚  â”‚  â€¢ update_space(space_id, config=None, ...)                  â”‚ â”‚
â”‚  â”‚    â†’ Update space (full or partial update)                   â”‚ â”‚
â”‚  â”‚  â€¢ trash_space(space_id)                                     â”‚ â”‚
â”‚  â”‚    â†’ Move space to trash (recoverable)                       â”‚ â”‚
â”‚  â”‚  â€¢ get_space_url(space_id)                                   â”‚ â”‚
â”‚  â”‚    â†’ Get UI URL for accessing space                          â”‚ â”‚
â”‚  â”‚                                                               â”‚ â”‚
â”‚  â”‚  Helper Functions:                                            â”‚ â”‚
â”‚  â”‚  â€¢ create_genie_space_from_file(config_path)                 â”‚ â”‚
â”‚  â”‚    â†’ Convenience function for file-based creation            â”‚ â”‚
â”‚  â”‚                                                               â”‚ â”‚
â”‚  â”‚  API Endpoints:                                               â”‚ â”‚
â”‚  â”‚  POST   /api/2.0/genie/spaces                                â”‚ â”‚
â”‚  â”‚  GET    /api/2.0/genie/spaces                                â”‚ â”‚
â”‚  â”‚  GET    /api/2.0/genie/spaces/{space_id}                     â”‚ â”‚
â”‚  â”‚  PATCH  /api/2.0/genie/spaces/{space_id}                     â”‚ â”‚
â”‚  â”‚  DELETE /api/2.0/genie/spaces/{space_id}                     â”‚ â”‚
â”‚  â”‚                                                               â”‚ â”‚
â”‚  â”‚  Features (2026 API):                                         â”‚ â”‚
â”‚  â”‚  âœ“ Pagination for large space lists                          â”‚ â”‚
â”‚  â”‚  âœ“ Partial updates (title, description only)                 â”‚ â”‚
â”‚  â”‚  âœ“ Serialized space export (requires CAN EDIT)               â”‚ â”‚
â”‚  â”‚  âœ“ Parent path for workspace organization                    â”‚ â”‚
â”‚  â”‚  âœ“ Trash (recoverable) vs permanent delete                   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATABRICKS GENIE SPACE                            â”‚
â”‚                                                                      â”‚
â”‚  â€¢ Space created/updated in workspace                                â”‚
â”‚  â€¢ Accessible via Databricks UI                                      â”‚
â”‚  â€¢ Ready for natural language queries                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Configuration Format Transformation

The system transforms between two formats:

#### User-Friendly Config (Generated by LLM)

```json
{
  "genie_space_config": {
    "space_name": "My Space",
    "tables": [...],
    "joins": [
      {
        "left_table": "catalog.schema.fact",
        "left_alias": "fact",
        "right_table": "catalog.schema.dim",
        "right_alias": "dim",
        "join_condition": "`fact`.`id` = `dim`.`id`",
        "relationship_type": "FROM_RELATIONSHIP_TYPE_MANY_TO_ONE"
      }
    ],
    "instructions": [
      {"content": "Use safe division..."}
    ],
    "example_sql_queries": [
      {
        "question": "Show revenue by category",
        "sql_query": "SELECT category, SUM(revenue)..."
      }
    ]
  }
}
```

#### Databricks Serialized Space Format

```json
{
  "version": 2,
  "data_sources": {
    "tables": [...]
  },
  "instructions": {
    "text_instructions": [
      {
        "id": "abc123...",
        "content": ["Use safe division...\n"]
      }
    ],
    "join_specs": [
      {
        "id": "def456...",
        "left": {"identifier": "...", "alias": "..."},
        "right": {"identifier": "...", "alias": "..."},
        "sql": [
          "`fact`.`id` = `dim`.`id`",
          "--rt=FROM_RELATIONSHIP_TYPE_MANY_TO_ONE--"
        ]
      }
    ],
    "example_question_sqls": [
      {
        "id": "ghi789...",
        "question": ["Show revenue by category\n"],
        "sql": ["SELECT category, SUM(revenue)...\n"]
      }
    ]
  },
  "benchmarks": {
    "questions": [...]
  }
}
```

### Key Transformation Rules

1. **All text fields become arrays of strings**
   - Single strings are split preserving newlines
   - Example: `"Hello\nWorld"` â†’ `["Hello\n", "World\n"]`

2. **Instructions are nested**
   - `instructions` â†’ `instructions.text_instructions`
   - `joins` â†’ `instructions.join_specs`
   - `example_sql_queries` â†’ `instructions.example_question_sqls`

3. **IDs are auto-generated**
   - Each instruction, join, and example gets a 24-char hex ID
   - Format: `01f0f7a0f1571de6bfd79fa6`

4. **Tables are sorted**
   - Sorted by identifier for consistency
   - Required by Databricks API

5. **Benchmarks are separate**
   - Not nested in `instructions`
   - Located at top-level `benchmarks.questions`

### Usage Examples

#### Creating a Genie Space

```python
from src.genie_space_client import GenieSpaceClient
import json

# Load the LLM-generated config
with open("output/genie_space_config.json") as f:
    config = json.load(f)

# Initialize client (reads from .env)
client = GenieSpaceClient()

# Create the space
response = client.create_space(
    config=config["genie_space_config"],
    parent_path="/Workspace/Users/me/genie_spaces"
)

print(f"Space ID: {response['space_id']}")
print(f"Space URL: {client.get_space_url(response['space_id'])}")
```

#### Updating a Genie Space

```python
# Update existing space
response = client.update_space(
    space_id="01f0f7a0f1571de6bfd79fa63ed872aa",
    config=updated_config
)
```

#### Fetching Space Configuration

```python
# Get space with full configuration
space_data = client.get_space(
    space_id="01f0f7a0f1571de6bfd79fa63ed872aa",
    include_serialized_space=True
)

# Parse the serialized_space
import json
serialized = json.loads(space_data["serialized_space"])
print(f"Tables: {len(serialized['data_sources']['tables'])}")
```

### API Request Flow

```
1. Client loads config from JSON
   â†“
2. GenieSpaceClient.create_space(config)
   â†“
3. config_transformer.transform_to_serialized_space(config)
   â†“
4. Build API payload:
   {
     "warehouse_id": "...",
     "title": "...",
     "description": "...",
     "serialized_space": "..." (JSON string)
   }
   â†“
5. POST to /api/2.0/genie/spaces
   â†“
6. Databricks creates Genie space
   â†“
7. Return space_id and metadata
```

### Environment Configuration

```bash
# .env file
DATABRICKS_HOST=https://your-workspace.cloud.databricks.com
DATABRICKS_TOKEN=dapi...
```

### Error Handling

Common errors and solutions:

| Error | Cause | Solution |
|-------|-------|----------|
| `warehouse_id is required` | Missing or placeholder warehouse ID | Update config with valid warehouse ID |
| `Invalid table identifier` | Malformed table name | Check catalog.schema.table format |
| `Authentication failed` | Invalid token | Verify DATABRICKS_TOKEN in .env |
| `Permission denied` | Insufficient permissions | Ensure CAN EDIT permission on space |
| `Table not found` | Table doesn't exist | Verify table exists in Unity Catalog |

### Complete Workflow Examples

#### Option 1: Automated Workflow (Recommended)

```bash
# Single command for end-to-end generation and creation
genie.py create --requirements sample/inputs/demo_requirements.md

# With custom options
genie.py create \
  --requirements sample/inputs/demo_requirements.md \
  --model databricks-gpt-5-2 \
  --max-tokens 16000 \
  --temperature 0.1 \
  --parent-path /Workspace/Users/your.email@domain.com/genie_spaces

# Output:
# - output/genie_space_config.json (generated config)
# - output/genie_space_result.json (space ID and URL)
```

#### Option 2: Manual Step-by-Step (For More Control)

```bash
# 1. Validate setup (optional but recommended)
python scripts/validate_setup.py

# 2. Parse documents if needed (async/concurrent with progress bars)
genie.py parse \
  --input-dir real_requirements/inputs \
  --output data/my_requirements.md \
  --max-concurrent 5

# 3. Generate config with LLM
genie.py generate \
  --requirements data/my_requirements.md \
  --model databricks-gpt-5-2 \
  --output output/genie_space_config.json

# 4. Validate tables and columns (RECOMMENDED)
genie.py validate --config output/genie_space_config.json
# Interactive prompts for catalog/schema replacement if validation fails

# 5. Review generated config
cat output/genie_space_config.json

# 6. (Optional) Edit warehouse_id, fix validation errors, etc.
vim output/genie_space_config.json

# 7. Re-validate if edited
genie.py validate --config output/genie_space_config.json

# 8. Deploy Genie space
genie.py deploy --config output/genie_space_config.json

# 9. Access your Genie space
# Space URL is printed and saved in output/genie_space_result.json
```

#### Option 3: Python API

```python
from src.genie_space_client import create_genie_space_from_file

# Create space from configuration file
result = create_genie_space_from_file('output/genie_space_config.json')
print(f'Space created: {result["space_url"]}')
print(f'Space ID: {result["space_id"]}')
```

#### Option 4: Direct API Call (curl)

```bash
# Transform config to serialized format
python -c "
from src.config_transformer import load_and_transform_config
import json

config, serialized = load_and_transform_config('output/genie_space_config.json')
payload = {
    'warehouse_id': config.get('warehouse_id'),
    'title': config.get('space_name'),
    'description': config.get('description'),
    'serialized_space': serialized
}
print(json.dumps(payload, indent=2))
" > payload.json

# Create space via API
curl -X POST https://workspace.cloud.databricks.com/api/2.0/genie/spaces \
  -H "Authorization: Bearer $DATABRICKS_TOKEN" \
  -H "Content-Type: application/json" \
  -d @payload.json
```

### Testing Transformations

```python
# Test the transformation
from src.config_transformer import transform_to_serialized_space
import json

config = {...}  # Your config
serialized = transform_to_serialized_space(config)
parsed = json.loads(serialized)

# Verify structure
assert parsed["version"] == 2
assert "data_sources" in parsed
assert "instructions" in parsed
assert "text_instructions" in parsed["instructions"]
assert "join_specs" in parsed["instructions"]
assert "example_question_sqls" in parsed["instructions"]
```

## Best Practices and Design Principles

### Configuration Generation Best Practices

1. **Start Small and Focused**
   - Begin with 3-5 core tables
   - Focus on a specific business domain
   - Expand incrementally based on feedback

2. **Use High-Quality Requirements**
   - Provide clear business context
   - Include specific example questions
   - Document table relationships
   - Specify metrics and dimensions

3. **Leverage Reasoning Models**
   - Use models like `databricks-gpt-5-2` for complex configurations
   - Increase `max_tokens` to 16000+ for reasoning models
   - Review reasoning output to understand configuration choices

4. **Iterate and Refine**
   - Generate multiple configurations with different temperatures
   - Review and edit generated configurations
   - Test with benchmark questions
   - Update requirements based on results

5. **Use Markdown-Formatted Instructions** (New in 2026)
   - LLM automatically generates well-structured instructions using markdown
   - Section headings (`##`) organize related instructions by topic
   - Bullet lists (`-`) group related rules and guidelines
   - **Bold text** emphasizes critical terms and actions
   - Inline `code` highlights column names, table names, and SQL keywords
   - Numbered lists show sequential steps or priorities
   - Blockquotes (`>`) format clarification questions
   - Benefits: Improved readability, easier maintenance, better organization

### Space Management Best Practices

1. **Validate Before Creation**
   - Run `python scripts/validate_setup.py` to check environment
   - **Run `genie.py validate` to verify tables and columns** (CRITICAL)
   - Verify `warehouse_id` is valid
   - Ensure all tables exist in Unity Catalog
   - Review generated configuration manually

2. **Table & Column Validation** (NEW)
   - Always validate before creating spaces
   - Fix errors (not warnings) before creation
   - Re-validate after editing configuration
   - Use `--json` flag for CI/CD integration
   - Review validation reports in detail

3. **Use Parent Paths for Organization**
   ```python
   client.create_space(
       config,
       parent_path="/Workspace/Users/your.email@domain.com/genie_spaces"
   )
   ```

4. **Implement Version Control**
   - Store configurations in git
   - Track changes to requirements documents
   - Maintain history of generated configs
   - Document reasoning for configuration choices
   - Save validation reports for audit trail

5. **Test Before Deployment**
   - Use benchmark questions to validate
   - Test common user queries
   - Verify table joins work correctly
   - Check metric calculations

### API Usage Best Practices

1. **Use Pagination for Large Lists**
   ```python
   page_token = None
   all_spaces = []
   while True:
       result = client.list_spaces(page_size=100, page_token=page_token)
       all_spaces.extend(result.get('spaces', []))
       page_token = result.get('next_page_token')
       if not page_token:
           break
   ```

2. **Prefer Partial Updates**
   ```python
   # Update only title without changing config
   client.update_space(space_id, title="New Title")
   ```

3. **Export Before Major Changes**
   ```python
   # Get full configuration before updating
   backup = client.get_space(space_id, include_serialized_space=True)
   with open('backup.json', 'w') as f:
       json.dump(backup, f)
   ```

4. **Use Trash Instead of Permanent Delete**
   ```python
   # Move to trash (recoverable)
   client.trash_space(space_id)
   ```

### Security and Credentials

1. **Never Commit Credentials**
   - Use `.env` files (add to `.gitignore`)
   - Use environment variables
   - Rotate tokens regularly
   - Use workspace-specific tokens

2. **Limit Token Permissions**
   - Use tokens with minimal required permissions
   - Create separate tokens for different environments
   - Monitor token usage

3. **Review Generated Configurations**
   - Check for sensitive data in descriptions
   - Verify table access permissions
   - Ensure appropriate warehouse selection

### Performance Optimization

1. **Optimize LLM Calls**
   - Cache prompt components
   - Reuse client connections
   - Batch operations when possible
   - Use appropriate `max_tokens` limits

2. **Optimize API Calls**
   - Use pagination for large result sets
   - Request only needed fields
   - Cache frequently accessed data
   - Implement rate limiting

3. **Configuration Size**
   - Keep instruction sets focused
   - Avoid redundant information
   - Use SQL expressions instead of repeated logic
   - Balance comprehensiveness with simplicity

### Error Handling and Debugging

1. **Enable Debug Logging**
   ```python
   import logging
   logging.basicConfig(level=logging.DEBUG)
   ```

2. **Capture and Log Errors**
   ```python
   try:
       result = client.create_space(config)
   except Exception as e:
       logging.error(f"Failed to create space: {e}")
       if hasattr(e, 'response'):
           logging.error(f"API response: {e.response.text}")
       raise
   ```

3. **Validate Incrementally**
   - Test prompt building independently
   - Validate JSON before API calls
   - Check transformations with small configs
   - Use unit tests for critical paths

4. **Common Issues and Solutions**

   | Issue | Cause | Solution |
   |-------|-------|----------|
   | `warehouse_id is required` | Missing or placeholder warehouse ID | Update config with valid warehouse ID |
   | `Invalid table identifier` | Malformed table name | Check `catalog.schema.table` format |
   | `Authentication failed` | Invalid token | Verify `DATABRICKS_TOKEN` in `.env` |
   | `Permission denied` | Insufficient permissions | Ensure CAN EDIT permission on space |
   | `Table not found` (at creation) | Table doesn't exist | Run `genie.py validate` first |
   | `Column not found` (at runtime) | Column doesn't exist | Run `genie.py validate` first |
   | Table validation fails | Table not in Unity Catalog | Check table exists with `SHOW TABLES` |
   | Column validation fails | Column name mismatch | Check column with `DESCRIBE TABLE` |
   | JSON parsing errors | Incomplete LLM response | Increase `max_tokens` parameter |
   | Validation errors | Schema mismatch | Review Pydantic model requirements |

### Development Workflow

1. **Local Development**
   ```bash
   # 1. Set up environment
   python -m venv .venv
   source .venv/bin/activate
   pip install -r requirements.txt
   cp .env.example .env
   # Edit .env with your credentials
   
   # 2. Validate setup
   python scripts/validate_setup.py
   
   # 3. Develop and test
   genie.py generate --requirements sample/inputs/demo_requirements.md
   
   # 4. Validate tables and columns (CRITICAL STEP)
   genie.py validate
   
   # 5. Fix any validation errors (interactive prompts available)
   # Validation can interactively fix catalog/schema issues
   
   # 6. Re-validate if manual edits were made
   genie.py validate
   
   # 7. Deploy space
   genie.py deploy
   ```

2. **Testing Strategy**
   - Unit test individual components
   - Integration test full workflows
   - Validate with real Databricks workspace
   - Test error conditions

3. **Code Quality**
   - Use type hints throughout
   - Document complex functions
   - Follow PEP 8 style guide
   - Keep functions focused and small

### Related Documentation

- **GENIE_CONFIG_GUIDE.md**: Detailed configuration format and structure guide
- **README.md**: Installation, quick start, and user guide
- **ARCHITECTURE.md** (this file): System architecture and design
- **TABLE_VALIDATION.md**: Complete table validation guide
- **VALIDATION_QUICK_REFERENCE.md**: Quick validation reference
- **Databricks Genie API**: https://docs.databricks.com/api/workspace/genie
- **Unity Catalog Docs**: Table and schema management

---

## Feedback Analysis System (New 2026)

### Overview

The Feedback Analysis System provides comprehensive tools for evaluating Genie Space quality by analyzing user questions, responses, and assessments. This enables data-driven improvements to space configurations.

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Feedback Data (Markdown)                        â”‚
â”‚  â€¢ Questions asked to Genie Space                            â”‚
â”‚  â€¢ Model responses (SQL or text)                             â”‚
â”‚  â€¢ Assessments (Good/Bad)                                    â”‚
â”‚  â€¢ Score reasons                                             â”‚
â”‚  â€¢ Ground truth SQL (if available)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FeedbackParser                                  â”‚
â”‚  â€¢ Parse feedback markdown entries                           â”‚
â”‚  â€¢ Extract questions, responses, assessments                 â”‚
â”‚  â€¢ Categorize failure reasons                                â”‚
â”‚  â€¢ Build structured data models                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Analysis & Export                               â”‚
â”‚                                                              â”‚
â”‚  analyze_feedback.py:                                        â”‚
â”‚  â€¢ Success rate statistics                                   â”‚
â”‚  â€¢ Failure reason breakdown                                  â”‚
â”‚  â€¢ Common error patterns                                     â”‚
â”‚  â€¢ Detailed entry examples                                   â”‚
â”‚                                                              â”‚
â”‚  export_feedback_csv.py:                                     â”‚
â”‚  â€¢ Summary CSV (high-level metrics)                          â”‚
â”‚  â€¢ Detailed CSV (per-question analysis)                      â”‚
â”‚  â€¢ Excel/Sheets compatible output                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Improvement Workflow                            â”‚
â”‚  1. Identify failure patterns                                â”‚
â”‚  2. Update instructions/examples                             â”‚
â”‚  3. Refine SQL expressions                                   â”‚
â”‚  4. Re-deploy improved configuration                         â”‚
â”‚  5. Re-test with same questions                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Feedback Entry Model

```python
@dataclass
class FeedbackEntry:
    question: str                # User question
    assessment: str              # "Good" or "Bad"
    score_reasons: List[str]     # Reasons for assessment
    
    # Model response
    model_output_type: str       # "SQL" or "text"
    model_output: str            # Actual response
    empty_result: bool           # No data returned
    
    # Failure analysis
    failure_reasoning: str       # Why it failed
    sql_differences: str         # Differences from ground truth
    
    # Ground truth
    ground_truth_sql: str        # Expected SQL
```

### Analysis Metrics

1. **Success Rate**: Percentage of "Good" assessments
2. **Failure Reasons**: Categorized error types
   - Incorrect table reference
   - Missing date filter
   - Wrong aggregation
   - Incomplete join
   - Hard-coded values
3. **Empty Results**: Queries returning no data
4. **SQL Comparison**: Ground truth vs model output differences

### Integration with Quality Workflow

```
Generate Config â†’ Deploy Space â†’ Test with Questions â†’ Collect Feedback
                                                              â†“
                                                      Analyze Feedback
                                                              â†“
                                        Identify Improvement Areas
                                                              â†“
                                        Update Configuration
                                                              â†“
                                              Re-deploy Space
                                                              â†“
                                           Re-test (Verify Improvements)
```

### Use Cases

1. **Quality Assessment**: Measure Genie Space accuracy
2. **Error Pattern Detection**: Find common failure modes
3. **Configuration Refinement**: Data-driven improvements
4. **Instruction Enhancement**: Add clarifications based on failures
5. **Benchmark Creation**: Use successful patterns as examples

### Output Formats

**Terminal Report** (analyze_feedback.py):
```
ðŸ“Š GENIE SPACE FEEDBACK ANALYSIS
================================================================================

ðŸ“ˆ Overall Statistics:
  â€¢ Total Questions: 150
  â€¢ Success Rate: 78.7%
  â€¢ Good Responses: 118
  â€¢ Bad Responses: 32
  â€¢ Empty Results: 5

âŒ Failure Reasons:
  â€¢ Incorrect table reference: 12 (8.0%)
  â€¢ Missing date filter: 10 (6.7%)
  â€¢ Wrong aggregation: 8 (5.3%)
  â€¢ Incomplete join: 2 (1.3%)
```

**CSV Export** (export_feedback_csv.py):
- `results_summary.csv`: One row per question
- `results_detailed.csv`: Expanded with SQL comparisons

---

## Table & Column Validation System

### Overview

The table validation system ensures that all customer-provided tables and columns referenced in a Genie space configuration actually exist in Databricks Unity Catalog before attempting to create the space.

### Why Validation Is Critical

**Without Validation:**
- âŒ Space creation may succeed but queries will fail at runtime
- âŒ Users see cryptic "table not found" or "column not found" errors
- âŒ Debugging is time-consuming and frustrating
- âŒ Poor user experience

**With Validation:**
- âœ… Catch errors before space creation
- âœ… Clear, actionable error messages
- âœ… Fast feedback loop for corrections
- âœ… Confident deployments

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Configuration (JSON)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          TableValidator                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ 1. Parse configuration                                 â”‚ â”‚
â”‚  â”‚ 2. Extract table references                            â”‚ â”‚
â”‚  â”‚ 3. Extract column references from SQL                  â”‚ â”‚
â”‚  â”‚ 4. Query Unity Catalog API                             â”‚ â”‚
â”‚  â”‚ 5. Validate existence and accessibility               â”‚ â”‚
â”‚  â”‚ 6. Generate comprehensive report                       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Unity Catalog API                                   â”‚
â”‚  â€¢ GET /unity-catalog/tables/{catalog}.{schema}.{table}    â”‚
â”‚  â€¢ Fallback: DESCRIBE TABLE via SQL execution              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          ValidationReport                                    â”‚
â”‚  â€¢ tables_valid / tables_invalid                            â”‚
â”‚  â€¢ columns_valid / columns_invalid                          â”‚
â”‚  â€¢ issues (errors, warnings, info)                          â”‚
â”‚  â€¢ Human-readable and JSON output                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### What Gets Validated

1. **Table Existence**
   - All tables in `tables` section
   - Checks against Unity Catalog
   - Verifies access permissions

2. **Column Existence**
   - Columns referenced in `sql_expressions`
   - Columns in `example_sql_queries`
   - Case-insensitive matching

3. **SQL Expression Parsing**
   - Extracts column references like `t.customer_id`
   - Maps aliases to tables (`t` â†’ `transactions`)
   - Validates against table schemas

### Key Features

- **Two-Tier API Strategy**: Unity Catalog API with SQL DESCRIBE fallback
- **Schema Caching**: Avoids redundant API calls
- **Case-Insensitive Matching**: Reduces false positives
- **Detailed Reporting**: Errors, warnings, and info levels
- **JSON Output**: CI/CD integration support
- **Interactive Replacement** (New): Two-mode catalog/schema/table name replacement
  - **Bulk Mode**: Replace catalog.schema for all tables at once
  - **Individual Mode**: Replace catalog.schema.table one by one (handles table name changes)
  - **Comprehensive Updates**: Automatically updates all references (SQL, joins, benchmarks, instructions)
  - **Join Alias Updates**: Updates join aliases when table names change (e.g., `orders` â†’ `transactions`)
  - **Up to 3 validation attempts** with automatic re-validation after updates

### Usage

```bash
# Basic validation
python scripts/validate_tables.py

# JSON output (for automation)
python scripts/validate_tables.py --json

# Verbose mode
python scripts/validate_tables.py --verbose
```

### Python API

```python
from src.table_validator import TableValidator

validator = TableValidator()

# Validate entire config
report = validator.validate_config("output/genie_space_config.json")

if report.has_errors():
    print(report.summary())
    exit(1)

# Validate specific table
exists = validator.validate_table("catalog", "schema", "table")

# Validate columns
results = validator.validate_columns(
    "catalog", "schema", "table",
    ["customer_id", "total_amount"]
)
```

### Integration Points

The validation system integrates at multiple points in the workflow:

1. **After Configuration Generation**
   ```bash
   genie.py generate --requirements data/requirements.md
   genie.py validate  # â† Validate here (interactive fixes)
   genie.py deploy
   ```

2. **Built into Create Command** (recommended)
   ```bash
   genie.py create --requirements data/requirements.md
   # Automatically validates and offers interactive replacement if needed
   # Automatically runs: generate â†’ validate â†’ deploy
   ```

3. **Before Space Creation** (critical when using Python API)
   - Always validate before calling create_space()
   - Fix errors, then re-validate
   - Only create space after validation passes

4. **In CI/CD Pipelines**
   ```yaml
   - run: genie.py validate --config output/genie_space_config.json
   # Returns non-zero exit code on validation failure
   ```

### Performance

- **First validation**: ~2-5 seconds (depends on table count)
- **Subsequent validations**: ~0.5-1 second (cached schemas)
- **API calls**: 1 per unique table (cached after first call)

### Error Handling

Common validation errors and solutions:

| Error | Solution |
|-------|----------|
| Table not found | Verify table exists: `SHOW TABLES IN catalog.schema` |
| Column not found | Check schema: `DESCRIBE TABLE catalog.schema.table` |
| Access denied | Verify READ permissions on table |
| API timeout | Check network connectivity, retry |

### Interactive Table Replacement (New)

When validation fails due to missing tables, the system offers interactive replacement to fix catalog/schema/table mismatches without manual editing.

**Two Replacement Modes:**

**Mode 1: Bulk Replacement**
- Replaces catalog.schema for all tables with the same catalog.schema combination
- Use when: Table names are consistent, but catalog/schema differs between environments
- Example: All `dev.sales.*` tables â†’ `prod.analytics.*`

**Mode 2: Individual Replacement**
- Replaces catalog.schema.table for each failed table individually
- Use when: Table names also differ between environments
- Example: `dev.sales.customer_data` â†’ `prod.analytics.customers`

**Automatic Updates:**
The replacement process updates ALL references throughout the configuration:
- âœ… Table definitions (catalog_name, schema_name, table_name)
- âœ… SQL expressions (full table references)
- âœ… Example SQL queries (full table references)
- âœ… Benchmark questions (expected_sql and table fields)
- âœ… Instructions (table references in content)
- âœ… Joins (left_table, right_table, join_condition)
- âœ… Join aliases (e.g., when `orders` â†’ `transactions`, also updates `orders.id` â†’ `transactions.id`)

**Workflow:**
```
1. Validation detects missing tables
2. System prompts user to choose mode:
   [1] Bulk replacement
   [2] Individual replacement
   [3] Cancel
3. User provides new catalog/schema/table names
   (Press Enter to keep current values)
4. System updates all references automatically
5. Re-validation runs automatically
6. Up to 3 validation attempts allowed
```

**Example:**
```bash
$ genie.py validate

âš ï¸  TABLE VALIDATION FAILED
Found 2 table(s) that were not found:
  1. dev.sales.customer_data
  2. dev.sales.order_history

Choose replacement mode:
  1. Bulk replacement (replace catalog.schema for all tables)
  2. Individual replacement (replace catalog.schema.table one by one)
  3. Cancel
Enter choice [1/2/3]: 2

Table 1/2: dev.sales.customer_data
  New catalog (current: dev): prod
  New schema (current: sales): analytics
  New table (current: customer_data): customers
  Updating dev.sales.customer_data â†’ prod.analytics.customers...
  âœ“ Updated:
     - 1 table(s)
     - 2 SQL expression(s)
     - 3 example query/queries
     - 2 benchmark question(s)
     - 1 instruction(s)
     - 1 join(s)

ðŸ”„ Configuration updated. Re-validating...
```

### Best Practices

1. **Always Validate**: Make it a required step in your workflow
2. **Fix Errors**: Errors must be fixed; warnings should be reviewed
3. **Use Interactive Replacement**: Let the system update all references automatically
4. **Save Reports**: Store validation results for audit trail
5. **Automate**: Use in CI/CD for automated validation
6. **Re-validate**: After any config changes, re-validate

### Documentation

For complete documentation:
- **Full Guide**: `docs/TABLE_VALIDATION.md`
- **Quick Reference**: `docs/VALIDATION_QUICK_REFERENCE.md`
- **Examples**: `examples/validate_tables_example.py`
- **Tests**: `tests/test_table_validator.py`

---

## Quick Reference

### Essential Commands

#### Setup and Validation
```bash
# Install dependencies
pip install -r requirements.txt

# Set up environment
cp .env.example .env
# Edit .env with your credentials

# Validate setup
python scripts/validate_setup.py

# Validate tables and columns (after generating config)
python scripts/validate_tables.py
python scripts/validate_tables.py --json  # JSON output
python scripts/validate_tables.py --verbose  # Verbose mode
```

#### Document Parsing
```bash
# Parse PDFs and markdown with concurrent processing
genie.py parse --input-dir docs/ --output data/requirements.md

# Parse with custom concurrency and models
genie.py parse \
  --input-dir docs/ \
  --output data/requirements.md \
  --max-concurrent 5 \
  --llm-model databricks-gpt-5-2 \
  --vision-model databricks-claude-sonnet-4

# Parse without LLM enrichment (faster)
genie.py parse --input-dir docs/ --output data/requirements.md --no-llm
```

#### Configuration Generation
```bash
# Generate with foundation model (recommended)
genie.py generate \
  --requirements sample/inputs/demo_requirements.md \
  --model databricks-gpt-5-2 \
  --max-tokens 16000 \
  --output output/genie_space_config.json

# Generate with custom endpoint
genie.py generate \
  --requirements sample/inputs/demo_requirements.md \
  --endpoint my-llm-endpoint \
  --output output/genie_space_config.json

# Generate without reasoning
genie.py generate --requirements data/demo_requirements.md --no-reasoning

# ðŸ†• Generate with custom benchmark batch size (NEW 2026)
genie.py generate \
  --requirements sample/inputs/demo_requirements.md \
  --benchmark-batch-size 5

# ðŸ†• Skip benchmark SQL generation (testing only, NEW 2026)
genie.py generate \
  --requirements sample/inputs/demo_requirements.md \
  --skip-benchmark-sql
```

#### Table Validation
```bash
# Validate tables and columns (with interactive fixes)
genie.py validate --config output/genie_space_config.json

# Validation includes:
# - Table existence in Unity Catalog
# - Column existence in tables
# - Interactive catalog/schema replacement on failures
# - Up to 3 validation attempts
```

#### Space Creation
```bash
# Deploy from configuration file
genie.py deploy \
  --config output/genie_space_config.json \
  --result-output output/genie_space_result.json

# Deploy with custom parent path
genie.py deploy \
  --config output/genie_space_config.json \
  --parent-path /Workspace/Users/your.email@domain.com/genie_spaces

# End-to-end automated workflow (recommended)
genie.py create --requirements sample/inputs/demo_requirements.md
```

### Key Python API Patterns

#### Document Parsing
```python
from src.pipeline import parse_documents
import asyncio

# Synchronous wrapper (async under the hood)
result = parse_documents(
    input_dir="docs/",
    output_path="data/requirements.md",
    llm_model="databricks-gpt-5-2",
    vision_model="databricks-claude-sonnet-4",
    use_llm=True,
    max_concurrent_pdfs=5
)

# Direct async usage
from src.pipeline.parser import parse_documents_async
result = asyncio.run(parse_documents_async(
    input_dir="docs/",
    output_path="data/requirements.md",
    max_concurrent_pdfs=5
))

print(f"Extracted: {result['questions_count']} questions, {result['tables_count']} tables")
```

#### Configuration Generation
```python
from src.pipeline import generate_config

# Generate configuration using pipeline function
config = generate_config(
    requirements_path="sample/inputs/demo_requirements.md",
    output_path="output/genie_space_config.json",
    model="databricks-gpt-5-2",
    max_tokens=16000,
    temperature=0.1
)

# Or use lower-level components
from src.prompt.prompt_builder import PromptBuilder
from src.llm.databricks_llm import DatabricksFoundationModelClient

builder = PromptBuilder(
    context_doc_path="genie/prompt/templates/curate_effective_genie.md",
    output_doc_path="genie/prompt/templates/genie_api.md",
    input_data_path="sample/inputs/demo_requirements.md"
)
prompt = builder.build_prompt_with_reasoning()

client = DatabricksFoundationModelClient(model_name="databricks-gpt-5-2")
response = client.generate_genie_config(prompt, max_tokens=16000)

import json
with open("output/genie_space_config.json", "w") as f:
    json.dump(response.model_dump(), f, indent=2)
```

#### Table & Column Validation
```python
from src.utils.table_validator import TableValidator

# Initialize validator
validator = TableValidator()

# Validate configuration
report = validator.validate_config("output/genie_space_config.json")

# Check for errors
if report.has_errors():
    print("âŒ Validation failed!")
    print(report.summary())
    exit(1)
else:
    print("âœ… All tables and columns are valid!")

# Validate specific table
exists = validator.validate_table("catalog", "schema", "table")

# Validate specific columns
results = validator.validate_columns(
    "catalog", "schema", "table",
    ["customer_id", "total_amount"]
)

# Get table schema
schema = validator.get_table_schema("catalog", "schema", "table")
for col in schema['columns']:
    print(f"  {col['name']}: {col['type_text']}")
```

#### Space Creation
```python
from src.api.genie_space_client import GenieSpaceClient, create_genie_space_from_file

# Method 1: Using convenience function
result = create_genie_space_from_file("output/genie_space_config.json")
print(f"Space URL: {result['space_url']}")

# Method 2: Using client directly
import json
client = GenieSpaceClient()

with open("output/genie_space_config.json") as f:
    config = json.load(f)

response = client.create_space(config)
space_id = response["space_id"]
print(f"Space ID: {space_id}")
```

#### Space Management
```python
from src.api.genie_space_client import GenieSpaceClient

client = GenieSpaceClient()

# List all spaces with pagination
spaces = client.list_spaces(page_size=100)
for space in spaces.get('spaces', []):
    print(f"{space['space_name']}: {space.get('space_id')}")

# Get space details
space = client.get_space(space_id)
print(f"Space: {space['space_name']}")

# Get space with full configuration (requires CAN EDIT)
space_full = client.get_space(space_id, include_serialized_space=True)

# Update space (partial)
client.update_space(
    space_id,
    title="Updated Title",
    description="New description"
)

# Update space (full config)
client.update_space(space_id, config=updated_config)

# Move to trash
client.trash_space(space_id)

# Get space URL
url = client.get_space_url(space_id)
print(f"Access at: {url}")
```

#### Configuration Transformation
```python
from src.utils.config_transformer import (
    transform_to_serialized_space,
    load_and_transform_config
)

# Transform config to serialized format
serialized = transform_to_serialized_space(config)

# Load and transform from file
config, serialized = load_and_transform_config("config.json")
```

### Key File Locations

| File | Purpose |
|------|---------|
| `genie.py` | ðŸŒŸ Unified CLI (parse, create, generate, validate, deploy) |
| `scripts/validate_setup.py` | Setup validation |
| `scripts/convert_requirements.py` | Requirements conversion |
| `scripts/auto_deploy.py` | Automated deployment with catalog replacement |
| `scripts/analyze_feedback.py` | Feedback analysis |
| `scripts/export_feedback_csv.py` | Feedback export to CSV |
| `examples/create_genie_space_example.py` | Python API examples |
| `genie/pipeline/parser.py` | Document parsing module (async/concurrent) |
| `genie/pipeline/generator.py` | Configuration generation module |
| `genie/pipeline/validator.py` | Table validation module |
| `genie/pipeline/deployer.py` | Space deployment module |
| `genie/models.py` | Pydantic schema models |
| `genie/prompt/prompt_builder.py` | Prompt construction |
| `genie/llm/databricks_llm.py` | Databricks LLM client |
| `genie/api/genie_space_client.py` | Genie Space API client |
| `genie/utils/config_transformer.py` | Config transformation |
| `genie/validation/table_validator.py` | Table & column validator |
| `genie/benchmark/benchmark_extractor.py` | Benchmark extractor (Pass 1) |
| `genie/benchmark/benchmark_loader.py` | Benchmark JSON loader |
| `genie/benchmark/benchmark_sql_generator.py` | Benchmark SQL generator (Pass 2) |
| `genie/extractor/domain_extractor.py` | Domain knowledge extractor |
| `genie/extractor/example_extractor.py` | Example SQL query extractor |
| `genie/extractor/table_extractor.py` | Table information extractor |
| `genie/validation/sql_validator.py` | SQL syntax & quality validator |
| `genie/validation/instruction_scorer.py` | Instruction quality scorer |
| `genie/utils/benchmark_sql_generator.py` | ðŸ†• Benchmark SQL generator (Pass 2, 2026) |
| `genie/parsing/pdf_parser.py` | PDF extraction (pdfplumber + LLM) with enhanced prompt |
| `genie/parsing/markdown_parser.py` | Markdown extraction (regex) with Phase 1 enhancements |
| `genie/parsing/requirements_structurer.py` | Data models & structuring (Phase 1 + Phase 2 fields) |
| `genie/parsing/llm_enricher.py` | LLM-based enrichment |
| `genie/parsing/markdown_generator.py` | Markdown output generation with 7 enhanced sections |
| `genie/parsing/formula_extractor.py` | ðŸ†• Formula pattern detection (Phase 2) |
| `genie/parsing/platform_analyzer.py` | ðŸ†• Platform-specific logic analysis (Phase 2) |
| `genie/parsing/feedback_parser.py` | Feedback analysis parser |
| `genie/prompt/templates/curate_effective_genie.md` | Best practices context |
| `genie/prompt/templates/genie_api.md` | API documentation |
| `genie/prompt/templates/benchmark_sql_prompt.md` | ðŸ†• Benchmark SQL prompt (2026) |
| `sample/inputs/demo_requirements.md` | Example requirements (Fashion Retail Analytics) |
| `sample/benchmarks/benchmarks.json` | Example benchmark questions |
| `output/genie_space_config.json` | Generated configuration |
| `output/genie_space_result.json` | Creation result |
| `tests/test_table_validator.py` | Table validator tests |
| `tests/test_join_specs.py` | Join specification tests |
| `tests/test_pdf_image_parsing.py` | PDF image parsing tests |
| `tests/test_benchmark_sql_generator.py` | ðŸ†• Benchmark SQL generator tests (16 tests, 2026) |
| `tests/test_enhanced_parsing.py` | ðŸ†• Enhanced parsing Phase 1 tests (26 tests, 2026) |
| `tests/test_phase2_parsing.py` | ðŸ†• Enhanced parsing Phase 2 tests (20 tests, 2026) |

### Environment Variables

```bash
# Required
DATABRICKS_HOST=https://your-workspace.databricks.com
DATABRICKS_TOKEN=dapi...

# Optional (with defaults)
LLM_MODEL=databricks-gpt-5-2                    # Text-based LLM for config generation
VISION_MODEL=databricks-claude-sonnet-4         # Vision model for PDF parsing
```

**Environment Variable Details**:

| Variable | Required | Default | Used By |
|----------|----------|---------|---------|
| `DATABRICKS_HOST` | âœ… Yes | - | All components |
| `DATABRICKS_TOKEN` | âœ… Yes | - | All components |
| `LLM_MODEL` | No | `databricks-gpt-5-2` | `parse`, `generate` commands |
| `VISION_MODEL` | No | `databricks-claude-sonnet-4` | `parse` command (PDF parsing) |

### Key Concepts

- **LLMResponse**: Wrapper containing config, reasoning, and confidence score
- **GenieSpaceConfig**: Main configuration model with all space settings
- **serialized_space**: Databricks internal format (auto-generated)
- **Transformation**: Conversion from user-friendly to serialized format
- **Pagination**: Handling large lists of spaces with page tokens
- **Partial Update**: Update only specific fields without full config
- **Trash**: Recoverable deletion (vs permanent delete)
- **Markdown-Formatted Instructions**: Instructions use markdown (headings, lists, bold, code) for better structure and readability

### Common Configuration Parameters

| Parameter | Default | Description |
|-----------|---------|-------------|
| `--model` | `databricks-gpt-5-2` | Foundation model to use |
| `--endpoint` | None | Custom serving endpoint |
| `--input-data` | `sample/inputs/demo_requirements.md` | Requirements document |
| `--output` | `output/genie_space_config.json` | Output file path |
| `--max-tokens` | 16000 | Maximum tokens to generate |
| `--temperature` | 0.1 | Sampling temperature (0.0-1.0) |
| `--no-reasoning` | False | Skip reasoning in output |

### Useful Aliases

```bash
# Add to ~/.bashrc or ~/.zshrc
alias genie='python genie.py'
alias genie-parse='python genie.py parse'
alias genie-generate='python genie.py generate'
alias genie-validate='python genie.py validate'
alias genie-deploy='python genie.py deploy'
alias genie-create='python genie.py create'

# With common options
alias genie-fast='python genie.py create --skip-validation -y'
alias genie-parse-fast='python genie.py parse --no-llm'
```

---

**End of Architecture Documentation**
