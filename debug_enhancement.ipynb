{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genie Enhancement v3 - Debug Notebook\n",
    "\n",
    "## Three-Space Architecture with Sequential Fixes\n",
    "\n",
    "**Safe enhancement workflow:**\n",
    "1. Clone production ‚Üí dev-working + dev-best\n",
    "2. Score benchmarks on dev-working\n",
    "3. Apply fixes ONE AT A TIME to dev-working\n",
    "4. After each fix: score ‚Üí keep if improved, rollback if worse\n",
    "5. Promote dev-best ‚Üí production (user decision)\n",
    "6. Cleanup dev spaces\n",
    "\n",
    "**Key Safety Features:**\n",
    "- Production is NEVER modified directly\n",
    "- Automatic rollback on score regression\n",
    "- User controls final promotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Clear cached modules to ensure latest code is loaded\n",
    "import sys\n",
    "\n",
    "modules_to_remove = [m for m in sys.modules if m.startswith('lib')]\n",
    "for m in modules_to_remove:\n",
    "    del sys.modules[m]\n",
    "\n",
    "print(f\"Cleared {len(modules_to_remove)} cached lib modules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project path setup\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Find project root\n",
    "current_path = Path(os.getcwd())\n",
    "if current_path.name == 'genie_enhancer':\n",
    "    project_root = current_path\n",
    "else:\n",
    "    project_root = current_path\n",
    "    while project_root.name != 'genie_enhancer' and project_root != project_root.parent:\n",
    "        project_root = project_root.parent\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Configure logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s | %(name)s | %(levelname)s | %(message)s',\n",
    "    datefmt='%H:%M:%S'\n",
    ")\n",
    "\n",
    "# Verbose logging for lib modules\n",
    "for module in ['lib.genie_client', 'lib.scorer', 'lib.llm', 'lib.enhancer', \n",
    "               'lib.applier', 'lib.space_api', 'lib.space_cloner', 'lib.sequential_enhancer']:\n",
    "    logging.getLogger(module).setLevel(logging.DEBUG)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Logging: DEBUG mode enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from lib.genie_client import GenieConversationalClient\n",
    "from lib.space_cloner import SpaceCloner\n",
    "from lib.scorer import BenchmarkScorer\n",
    "from lib.benchmark_parser import BenchmarkLoader\n",
    "from lib.llm import DatabricksLLMClient\n",
    "from lib.sql import SQLExecutor\n",
    "from lib.sequential_enhancer import SequentialEnhancer\n",
    "\n",
    "print(\"‚úÖ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === UPDATE THESE VALUES ===\n",
    "DATABRICKS_HOST = \"your-workspace.cloud.databricks.com\"\n",
    "DATABRICKS_TOKEN = \"YOUR_TOKEN_HERE\"\n",
    "GENIE_SPACE_ID = \"your-space-id\"  # Production space to enhance\n",
    "WAREHOUSE_ID = \"your-warehouse-id\"  # For metric views\n",
    "LLM_ENDPOINT = \"databricks-claude-sonnet-4\"\n",
    "\n",
    "# Enhancement settings\n",
    "TARGET_SCORE = 0.90\n",
    "INDEXING_WAIT = 60  # seconds to wait after each change\n",
    "\n",
    "print(f\"Host: {DATABRICKS_HOST}\")\n",
    "print(f\"Production Space: {GENIE_SPACE_ID}\")\n",
    "print(f\"Warehouse: {WAREHOUSE_ID}\")\n",
    "print(f\"LLM: {LLM_ENDPOINT}\")\n",
    "print(f\"Target: {TARGET_SCORE:.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Initialize Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space Cloner (for three-space architecture)\n",
    "print(\"Initializing Space Cloner...\")\n",
    "space_cloner = SpaceCloner(\n",
    "    host=DATABRICKS_HOST,\n",
    "    token=DATABRICKS_TOKEN\n",
    ")\n",
    "print(\"‚úÖ Space Cloner initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Client (with rate limit protection)\n",
    "print(\"Initializing LLM Client...\")\n",
    "llm_client = DatabricksLLMClient(\n",
    "    host=DATABRICKS_HOST,\n",
    "    token=DATABRICKS_TOKEN,\n",
    "    endpoint_name=LLM_ENDPOINT,\n",
    "    request_delay=10.0,          # 10s delay between requests\n",
    "    rate_limit_base_delay=90.0   # 90s base on rate limit\n",
    ")\n",
    "\n",
    "if llm_client.test_connection():\n",
    "    print(\"‚úÖ LLM Client connected\")\n",
    "    print(\"   - Request delay: 10s\")\n",
    "    print(\"   - Rate limit backoff: 90s base\")\n",
    "else:\n",
    "    print(\"‚ùå LLM connection failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL Executor (for metric views)\n",
    "print(\"Initializing SQL Executor...\")\n",
    "sql_executor = SQLExecutor(\n",
    "    host=DATABRICKS_HOST,\n",
    "    token=DATABRICKS_TOKEN,\n",
    "    warehouse_id=WAREHOUSE_ID\n",
    ")\n",
    "print(\"‚úÖ SQL Executor initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Load Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load benchmarks\n",
    "benchmark_file = project_root / \"benchmarks\" / \"benchmarks.json\"\n",
    "print(f\"Loading from: {benchmark_file}\")\n",
    "\n",
    "loader = BenchmarkLoader(str(benchmark_file))\n",
    "all_benchmarks = loader.load()\n",
    "print(f\"‚úÖ Loaded {len(all_benchmarks)} benchmarks\")\n",
    "\n",
    "# Preview\n",
    "for i, b in enumerate(all_benchmarks[:3]):\n",
    "    print(f\"  {i+1}. {b['question'][:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Use subset for faster testing\n",
    "USE_SUBSET = True  # Set to False for full run\n",
    "\n",
    "if USE_SUBSET:\n",
    "    benchmarks = all_benchmarks[:5]  # First 5 only\n",
    "    print(f\"‚ö†Ô∏è TEST MODE: Using {len(benchmarks)} benchmarks\")\n",
    "else:\n",
    "    benchmarks = all_benchmarks\n",
    "    print(f\"FULL MODE: Using {len(benchmarks)} benchmarks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5Ô∏è‚É£ Setup Three-Space Architecture\n",
    "\n",
    "This creates:\n",
    "- **Production** - Original space (never modified)\n",
    "- **Dev-Working** - Where changes are tested\n",
    "- **Dev-Best** - Holds best configuration (for rollback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"SETTING UP THREE-SPACE ARCHITECTURE\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(f\"Production Space: {GENIE_SPACE_ID}\")\n",
    "print(\"Creating dev-working and dev-best clones...\")\n",
    "print()\n",
    "\n",
    "setup_result = space_cloner.setup_three_spaces(\n",
    "    production_space_id=GENIE_SPACE_ID\n",
    ")\n",
    "\n",
    "if setup_result['success']:\n",
    "    print()\n",
    "    print(\"=\"*60)\n",
    "    print(\"THREE-SPACE ARCHITECTURE READY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Production:   {setup_result['production_id']}\")\n",
    "    print(f\"Dev-Working:  {setup_result['dev_working_id']}\")\n",
    "    print(f\"Dev-Best:     {setup_result['dev_best_id']}\")\n",
    "    \n",
    "    # Store for later\n",
    "    PRODUCTION_ID = setup_result['production_id']\n",
    "    DEV_WORKING_ID = setup_result['dev_working_id']\n",
    "    DEV_BEST_ID = setup_result['dev_best_id']\n",
    "    INITIAL_CONFIG = setup_result['initial_config']\n",
    "else:\n",
    "    print(f\"‚ùå Setup failed: {setup_result['error']}\")\n",
    "    raise RuntimeError(\"Three-space setup failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Initialize Scorer and Enhancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genie Client pointing to DEV-WORKING space\n",
    "print(\"Initializing Genie Client for dev-working space...\")\n",
    "genie_client = GenieConversationalClient(\n",
    "    host=DATABRICKS_HOST,\n",
    "    token=DATABRICKS_TOKEN,\n",
    "    space_id=DEV_WORKING_ID,  # Point to dev-working, NOT production\n",
    "    verbose=True\n",
    ")\n",
    "print(f\"‚úÖ Genie Client initialized (space: {DEV_WORKING_ID[:16]}...)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark Scorer\n",
    "print(\"Initializing Scorer...\")\n",
    "scorer = BenchmarkScorer(\n",
    "    genie_client=genie_client,\n",
    "    llm_client=llm_client,\n",
    "    sql_executor=sql_executor,\n",
    "    config={\n",
    "        \"question_timeout\": 120,\n",
    "        \"question_delay\": 3.0,\n",
    "        \"error_delay\": 5.0,\n",
    "        \"parallel_workers\": 0,  # Sequential for debugging\n",
    "    }\n",
    ")\n",
    "print(\"‚úÖ Scorer initialized (sequential mode)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Enhancer (orchestrates the whole flow)\n",
    "print(\"Initializing Sequential Enhancer...\")\n",
    "enhancer = SequentialEnhancer(\n",
    "    llm_client=llm_client,\n",
    "    space_cloner=space_cloner,\n",
    "    scorer=scorer,\n",
    "    sql_executor=sql_executor\n",
    ")\n",
    "print(\"‚úÖ Sequential Enhancer initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7Ô∏è‚É£ Initial Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"INITIAL SCORING (on dev-working)\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "start_time = datetime.now()\n",
    "initial_results = scorer.score(benchmarks)\n",
    "duration = (datetime.now() - start_time).total_seconds()\n",
    "\n",
    "print()\n",
    "print(\"=\"*60)\n",
    "print(\"INITIAL SCORING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Score: {initial_results['score']:.1%}\")\n",
    "print(f\"Passed: {initial_results['passed']}/{initial_results['total']}\")\n",
    "print(f\"Failed: {initial_results['failed']}\")\n",
    "print(f\"Duration: {duration:.1f}s\")\n",
    "\n",
    "# Check if already at target\n",
    "if initial_results['score'] >= TARGET_SCORE:\n",
    "    print()\n",
    "    print(\"üéâ Already at target score! No enhancement needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show failed benchmarks\n",
    "failed_results = [r for r in initial_results['results'] if not r['passed']]\n",
    "\n",
    "print(f\"\\n‚ùå Failed Benchmarks ({len(failed_results)}):\\n\")\n",
    "for i, r in enumerate(failed_results, 1):\n",
    "    print(f\"{i}. {r['question'][:60]}...\")\n",
    "    print(f\"   Category: {r.get('failure_category', 'unknown')}\")\n",
    "    if r.get('failure_reason'):\n",
    "        print(f\"   Reason: {r['failure_reason'][:80]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8Ô∏è‚É£ Generate Enhancement Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"GENERATING ENHANCEMENT PLAN\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(f\"Analyzing {len(failed_results)} failures...\")\n",
    "print(\"Categories: metric_view, metadata, sample_query, instruction\")\n",
    "print()\n",
    "\n",
    "plan_start = datetime.now()\n",
    "grouped_fixes = enhancer.analyze_all_failures(\n",
    "    benchmark_results=initial_results,\n",
    "    space_config=INITIAL_CONFIG,\n",
    "    parallel_workers=1  # Sequential to avoid rate limits\n",
    ")\n",
    "plan_duration = (datetime.now() - plan_start).total_seconds()\n",
    "\n",
    "total_fixes = sum(len(f) for f in grouped_fixes.values())\n",
    "print()\n",
    "print(\"=\"*60)\n",
    "print(\"PLAN GENERATION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total fixes: {total_fixes}\")\n",
    "print(f\"Duration: {plan_duration:.1f}s\")\n",
    "\n",
    "for category in ['metric_view', 'metadata', 'sample_query', 'instruction']:\n",
    "    count = len(grouped_fixes.get(category, []))\n",
    "    print(f\"  - {category}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview fixes\n",
    "print(\"\\nFix Preview:\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "for category in ['metric_view', 'metadata', 'sample_query', 'instruction']:\n",
    "    fixes = grouped_fixes.get(category, [])\n",
    "    if fixes:\n",
    "        print(f\"\\n{category.upper()} ({len(fixes)} fixes):\")\n",
    "        for i, fix in enumerate(fixes[:3], 1):  # Show first 3\n",
    "            fix_type = fix.get('type', 'unknown')\n",
    "            if fix_type == 'add_synonym':\n",
    "                print(f\"  {i}. {fix_type}: {fix.get('table')}.{fix.get('column')} ‚Üí '{fix.get('synonym')}'\")\n",
    "            elif fix_type == 'add_column_description':\n",
    "                print(f\"  {i}. {fix_type}: {fix.get('table')}.{fix.get('column')}\")\n",
    "            else:\n",
    "                print(f\"  {i}. {fix_type}\")\n",
    "        if len(fixes) > 3:\n",
    "            print(f\"  ... and {len(fixes) - 3} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9Ô∏è‚É£ Run Sequential Enhancement Loop\n",
    "\n",
    "This applies fixes one at a time:\n",
    "- Apply fix to dev-working\n",
    "- Wait for indexing\n",
    "- Score benchmarks\n",
    "- If improved: keep fix, update dev-best\n",
    "- If worse: rollback from dev-best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"SEQUENTIAL ENHANCEMENT LOOP\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(f\"Total fixes to try: {total_fixes}\")\n",
    "print(f\"Indexing wait: {INDEXING_WAIT}s per fix\")\n",
    "print(f\"Estimated time: ~{total_fixes * (INDEXING_WAIT + 60) / 60:.0f} minutes\")\n",
    "print()\n",
    "print(\"Starting...\")\n",
    "print()\n",
    "\n",
    "loop_start = datetime.now()\n",
    "loop_result = enhancer.run_sequential_loop(\n",
    "    benchmarks=benchmarks,\n",
    "    grouped_fixes=grouped_fixes,\n",
    "    indexing_wait_time=INDEXING_WAIT,\n",
    "    target_score=TARGET_SCORE\n",
    ")\n",
    "loop_duration = (datetime.now() - loop_start).total_seconds()\n",
    "\n",
    "print()\n",
    "print(\"=\"*60)\n",
    "print(\"ENHANCEMENT LOOP COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Initial Score: {loop_result['initial_score']:.1%}\")\n",
    "print(f\"Final Score:   {loop_result['final_score']:.1%}\")\n",
    "print(f\"Improvement:   {loop_result['final_score'] - loop_result['initial_score']:+.1%}\")\n",
    "print(f\"Fixes Applied: {len(loop_result['fixes_applied'])}\")\n",
    "print(f\"Fixes Rejected: {len(loop_result['fixes_rejected'])}\")\n",
    "print(f\"Duration:      {loop_duration:.1f}s ({loop_duration/60:.1f} min)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show applied fixes\n",
    "if loop_result['fixes_applied']:\n",
    "    print(\"\\n‚úÖ Applied Fixes:\")\n",
    "    for i, fix in enumerate(loop_result['fixes_applied'], 1):\n",
    "        print(f\"  {i}. {fix.get('type')}\")\n",
    "\n",
    "# Show rejected fixes\n",
    "if loop_result['fixes_rejected']:\n",
    "    print(f\"\\n‚ùå Rejected Fixes ({len(loop_result['fixes_rejected'])})\")\n",
    "    for i, fix in enumerate(loop_result['fixes_rejected'][:5], 1):\n",
    "        print(f\"  {i}. {fix.get('type')}: {fix.get('rejection_reason', 'N/A')[:50]}\")\n",
    "    if len(loop_result['fixes_rejected']) > 5:\n",
    "        print(f\"  ... and {len(loop_result['fixes_rejected']) - 5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üîü Promotion Decision\n",
    "\n",
    "**Your options:**\n",
    "1. **Promote** - Apply dev-best config to production\n",
    "2. **Keep for review** - Leave dev spaces for manual inspection\n",
    "3. **Discard** - Delete dev spaces, keep production unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"=\"*60)\n",
    "print(\"ENHANCEMENT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(f\"Production Space: {PRODUCTION_ID}\")\n",
    "print(f\"Dev-Best Space:   {DEV_BEST_ID}\")\n",
    "print(f\"Dev-Working:      {DEV_WORKING_ID}\")\n",
    "print()\n",
    "print(f\"Initial Score: {loop_result['initial_score']:.1%}\")\n",
    "print(f\"Best Score:    {loop_result['final_score']:.1%}\")\n",
    "print(f\"Improvement:   {loop_result['final_score'] - loop_result['initial_score']:+.1%}\")\n",
    "print()\n",
    "print(\"Ready for your decision:\")\n",
    "print(\"  1. Run 'Promote to Production' cell to apply changes\")\n",
    "print(\"  2. Run 'Cleanup' cell to discard and keep production unchanged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 1: Promote to Production\n",
    "# WARNING: This will modify your production Genie Space!\n",
    "\n",
    "CONFIRM_PROMOTE = False  # Set to True to enable\n",
    "\n",
    "if CONFIRM_PROMOTE:\n",
    "    print(\"Promoting dev-best to production...\")\n",
    "    promote_result = space_cloner.promote_to_production()\n",
    "    \n",
    "    if promote_result['success']:\n",
    "        print(\"‚úÖ Production updated with best configuration!\")\n",
    "        \n",
    "        # Cleanup dev spaces\n",
    "        print(\"\\nCleaning up dev spaces...\")\n",
    "        cleanup_result = space_cloner.cleanup_dev_spaces()\n",
    "        if cleanup_result['success']:\n",
    "            print(\"‚úÖ Dev spaces deleted\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Cleanup warning: {cleanup_result['error']}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Promotion failed: {promote_result['error']}\")\n",
    "else:\n",
    "    print(\"Set CONFIRM_PROMOTE = True to promote dev-best to production\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 2: Cleanup without promoting\n",
    "# This discards all changes and keeps production unchanged\n",
    "\n",
    "CONFIRM_CLEANUP = False  # Set to True to enable\n",
    "\n",
    "if CONFIRM_CLEANUP:\n",
    "    print(\"Cleaning up dev spaces (no changes to production)...\")\n",
    "    cleanup_result = space_cloner.cleanup_dev_spaces()\n",
    "    \n",
    "    if cleanup_result['success']:\n",
    "        print(\"‚úÖ Dev spaces deleted\")\n",
    "        print(\"Production space unchanged.\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Cleanup warning: {cleanup_result['error']}\")\n",
    "else:\n",
    "    print(\"Set CONFIRM_CLEANUP = True to delete dev spaces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Debug Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to JSON\n",
    "output = {\n",
    "    \"production_id\": PRODUCTION_ID,\n",
    "    \"dev_working_id\": DEV_WORKING_ID,\n",
    "    \"dev_best_id\": DEV_BEST_ID,\n",
    "    \"initial_score\": loop_result['initial_score'],\n",
    "    \"final_score\": loop_result['final_score'],\n",
    "    \"fixes_applied\": len(loop_result['fixes_applied']),\n",
    "    \"fixes_rejected\": len(loop_result['fixes_rejected']),\n",
    "}\n",
    "\n",
    "with open('enhancement_result.json', 'w') as f:\n",
    "    json.dump(output, f, indent=2)\n",
    "print(\"‚úÖ Results saved to enhancement_result.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Genie on dev-working\n",
    "test_question = \"What tables are available?\"\n",
    "print(f\"Testing Genie (dev-working): {test_question}\")\n",
    "\n",
    "response = genie_client.ask(test_question, timeout=60)\n",
    "print(f\"Status: {response['status']}\")\n",
    "if response.get('sql'):\n",
    "    print(f\"SQL: {response['sql'][:100]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
