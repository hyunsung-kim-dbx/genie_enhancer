{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genie Space Enhancement V2 - Debug Notebook\n",
    "\n",
    "## Three-Space Architecture with Sequential Fixes\n",
    "\n",
    "This notebook tests the V2 enhancement workflow:\n",
    "\n",
    "1. **Three-Space Architecture**\n",
    "   - Production: Original space (never modified)\n",
    "   - Dev-Best: Best-performing configuration\n",
    "   - Dev-Working: Where changes are tested\n",
    "\n",
    "2. **Four Fix Types Only**\n",
    "   - Metric Views (create/delete)\n",
    "   - Metadata (descriptions, synonyms)\n",
    "   - Sample Queries (parameterized templates)\n",
    "   - Instructions (text instructions)\n",
    "\n",
    "3. **Sequential Evaluation**\n",
    "   - Apply one fix ‚Üí Evaluate ‚Üí Update best or rollback\n",
    "   - ~40 minutes per full loop\n",
    "\n",
    "## Usage\n",
    "1. Run cells in order\n",
    "2. Check intermediate results\n",
    "3. At the end, decide whether to promote to production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project path setup\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Find project root\n",
    "current_path = Path(os.getcwd())\n",
    "if current_path.name == 'genie_enhancer':\n",
    "    project_root = current_path\n",
    "else:\n",
    "    search_path = current_path\n",
    "    while search_path.name != 'genie_enhancer' and search_path != search_path.parent:\n",
    "        search_path = search_path.parent\n",
    "    project_root = search_path if search_path.name == 'genie_enhancer' else current_path\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"‚úÖ Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import modules (updated for v3 lib/ structure)\nimport json\nimport yaml\nimport pandas as pd\nfrom datetime import datetime\n\nfrom lib.genie_client import GenieConversationalClient\nfrom lib.space_api import SpaceUpdater\nfrom lib.scorer import BenchmarkScorer\nfrom lib.benchmark_parser import BenchmarkLoader\nfrom lib.llm import DatabricksLLMClient\nfrom lib.sql import SQLExecutor\n\n# V3 Components (Batch Apply)\nfrom lib.space_cloner import SpaceCloner\nfrom lib.enhancer import EnhancementPlanner\nfrom lib.applier import BatchApplier\n\nprint(\"‚úÖ All modules imported successfully\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load configuration from config/app.yaml\nconfig_path = 'config/app.yaml'\nif os.path.exists(config_path):\n    with open(config_path, 'r') as f:\n        app_config = yaml.safe_load(f)\n\n    for env_var in app_config.get('env', []):\n        name = env_var.get('name')\n        value = env_var.get('value')\n        os.environ[name] = value\n        print(f\"{name} = {value}\")\n\n    print(\"\\n‚úÖ config/app.yaml loaded\")\nelse:\n    print(f\"‚ö†Ô∏è {config_path} not found - using manual configuration below\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Connection settings (update with your values)\n# === GENIE SPACE CONNECTION ===\nDATABRICKS_HOST = \"your-workspace.cloud.databricks.com\"  # Genie Space host\nDATABRICKS_TOKEN = \"YOUR_TOKEN_HERE\"  # Genie token - TODO: Update\nGENIE_SPACE_ID = \"your-space-id\"  # Production space ID\nWAREHOUSE_ID = \"your-warehouse-id\"  # Required for metric views\n\n# === LLM CONNECTION (can be different!) ===\nLLM_HOST = \"your-workspace.cloud.databricks.com\"  # LLM host - TODO: Change if different\nLLM_TOKEN = \"YOUR_LLM_TOKEN_HERE\"  # LLM token - TODO: Set your LLM token (different from Genie!)\nLLM_ENDPOINT = \"databricks-claude-sonnet-4\"  # Model endpoint\n\nos.environ['DATABRICKS_HOST'] = DATABRICKS_HOST\nos.environ['DATABRICKS_TOKEN'] = DATABRICKS_TOKEN\nos.environ['GENIE_SPACE_ID'] = GENIE_SPACE_ID\n\nprint(f\"=== Genie Connection ===\")\nprint(f\"  Host: {DATABRICKS_HOST}\")\nprint(f\"  Token: {DATABRICKS_TOKEN[:10]}...{DATABRICKS_TOKEN[-4:] if len(DATABRICKS_TOKEN) > 14 else '(set your token!)'}\")\nprint(f\"  Space ID: {GENIE_SPACE_ID}\")\nprint(f\"\\n=== LLM Connection ===\")\nprint(f\"  Host: {LLM_HOST}\")\nprint(f\"  Token: {LLM_TOKEN[:10]}...{LLM_TOKEN[-4:] if len(LLM_TOKEN) > 14 else '(set your token!)'}\")\nprint(f\"  Endpoint: {LLM_ENDPOINT}\")\nprint(f\"\\n‚úÖ Connection settings configured\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Initialize Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Space Cloner (for three-space architecture)\n",
    "print(\"Initializing Space Cloner...\")\n",
    "space_cloner = SpaceCloner(\n",
    "    host=DATABRICKS_HOST,\n",
    "    token=DATABRICKS_TOKEN\n",
    ")\n",
    "print(\"‚úÖ Space Cloner initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize LLM Client (uses LLM_HOST, can be different from Genie host)\nprint(f\"Initializing LLM Client...\")\nprint(f\"  Host: {LLM_HOST}\")\nprint(f\"  Endpoint: {LLM_ENDPOINT}\")\n\nllm_client = DatabricksLLMClient(\n    host=LLM_HOST,      # Uses LLM host (can be different from DATABRICKS_HOST)\n    token=LLM_TOKEN,    # Uses LLM token\n    endpoint_name=LLM_ENDPOINT\n)\n\nif llm_client.test_connection():\n    print(f\"‚úÖ LLM Client initialized and connected\")\nelse:\n    print(\"‚ùå LLM connection failed\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Setup Three-Space Architecture\n",
    "\n",
    "This creates:\n",
    "- `{SpaceName}_dev_working` - Where changes are tested\n",
    "- `{SpaceName}_dev_best` - Best-performing configuration\n",
    "\n",
    "Production space is **never modified**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup three-space architecture\n",
    "print(\"Setting up Three-Space Architecture...\")\n",
    "print(\"(This will clone the production space)\\n\")\n",
    "\n",
    "setup_result = space_cloner.setup_three_spaces(\n",
    "    production_space_id=GENIE_SPACE_ID,\n",
    "    working_suffix=\"_dev_working\",\n",
    "    best_suffix=\"_dev_best\"\n",
    ")\n",
    "\n",
    "if setup_result[\"success\"]:\n",
    "    print(f\"\\n‚úÖ Three-Space Architecture Ready!\")\n",
    "    print(f\"\\nSpace IDs:\")\n",
    "    print(f\"  Production:   {setup_result['production_id']}\")\n",
    "    print(f\"  Dev-Working:  {setup_result['dev_working_id']}\")\n",
    "    print(f\"  Dev-Best:     {setup_result['dev_best_id']}\")\n",
    "    print(f\"\\nProduction Name: {setup_result['production_name']}\")\n",
    "    \n",
    "    # Store for later use\n",
    "    PRODUCTION_ID = setup_result['production_id']\n",
    "    DEV_WORKING_ID = setup_result['dev_working_id']\n",
    "    DEV_BEST_ID = setup_result['dev_best_id']\n",
    "    initial_config = setup_result['initial_config']\n",
    "else:\n",
    "    print(f\"‚ùå Setup failed: {setup_result['error']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Genie Client for DEV-WORKING space\n",
    "print(f\"Initializing Genie Client for dev-working space...\")\n",
    "genie_client = GenieConversationalClient(\n",
    "    host=DATABRICKS_HOST,\n",
    "    token=DATABRICKS_TOKEN,\n",
    "    space_id=DEV_WORKING_ID,  # Use dev-working for testing\n",
    "    verbose=True\n",
    ")\n",
    "print(f\"‚úÖ Genie Client initialized (space: {DEV_WORKING_ID})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick API test on dev-working\n",
    "print(\"Testing dev-working space...\")\n",
    "test_response = genie_client.ask(\"What tables are available?\", timeout=60)\n",
    "print(f\"Status: {test_response['status']}\")\n",
    "if test_response['status'] == 'COMPLETED':\n",
    "    print(\"‚úÖ Dev-working space is functional\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Response: {test_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Load Benchmarks & Initial Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load benchmarks\n",
    "benchmark_file = \"benchmarks/benchmarks.json\"\n",
    "print(f\"Loading benchmarks from: {benchmark_file}\")\n",
    "\n",
    "loader = BenchmarkLoader(benchmark_file)\n",
    "all_benchmarks = loader.load()\n",
    "print(f\"\\n‚úÖ Loaded {len(all_benchmarks)} total benchmarks\")\n",
    "\n",
    "# Filter for testing (optional)\n",
    "TEST_MODE = True\n",
    "if TEST_MODE:\n",
    "    # Use subset for faster testing\n",
    "    benchmarks = [x for x in all_benchmarks if x['source_file']=='social_analytics_benchmark.md']\n",
    "    print(f\"‚ö†Ô∏è TEST MODE: Using {len(benchmarks)} benchmarks\")\n",
    "else:\n",
    "    benchmarks = all_benchmarks\n",
    "    print(f\"FULL MODE: Using {len(benchmarks)} benchmarks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize Benchmark Scorer\nprint(\"Initializing Benchmark Scorer...\")\nscorer = BenchmarkScorer(\n    genie_client=genie_client,\n    llm_client=llm_client,\n    config={\n        \"parallel_workers\": 2,      # Run 2 questions at once\n        \"question_timeout\": 180     # 3 min timeout per question\n    }\n)\nprint(\"‚úÖ Scorer initialized (parallel_workers=2)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run initial scoring on dev-working\n",
    "print(\"Scoring initial state on dev-working space...\")\n",
    "print(\"(This may take a few minutes)\\n\")\n",
    "\n",
    "initial_results = scorer.score(benchmarks)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"INITIAL BENCHMARK RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Score: {initial_results['score']:.1%}\")\n",
    "print(f\"Passed: {initial_results['passed']}/{initial_results['total']}\")\n",
    "print(f\"Failed: {initial_results['failed']}/{initial_results['total']}\")\n",
    "print(f\"Duration: {initial_results['duration_seconds']:.1f}s\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show failed benchmarks\n",
    "failed_results = [r for r in initial_results['results'] if not r['passed']]\n",
    "\n",
    "if failed_results:\n",
    "    print(f\"\\n‚ùå Failed Benchmarks ({len(failed_results)}):\\n\")\n",
    "    for i, result in enumerate(failed_results, 1):\n",
    "        print(f\"{i}. {result['question'][:70]}...\")\n",
    "        print(f\"   Category: {result.get('failure_category', 'unknown')}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Analyze Failures & Generate Fixes\n",
    "\n",
    "Using the simplified prompt with **only 4 fix types**:\n",
    "1. Metric Views\n",
    "2. Metadata (descriptions, synonyms)\n",
    "3. Sample Queries\n",
    "4. Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize Sequential Enhancer with SQL Executor for metric views\nprint(\"Initializing SQL Executor...\")\nsql_executor = SQLExecutor(\n    host=DATABRICKS_HOST,\n    token=DATABRICKS_TOKEN,\n    warehouse_id=WAREHOUSE_ID\n)\nprint(f\"‚úÖ SQL Executor initialized (warehouse: {WAREHOUSE_ID})\")\n\nprint(\"Initializing Sequential Enhancer...\")\nsequential_enhancer = SequentialEnhancer(\n    llm_client=llm_client,\n    space_cloner=space_cloner,\n    scorer=scorer,\n    sql_executor=sql_executor,  # For creating metric views in Unity Catalog\n    config={\n        \"catalog\": \"sandbox\",\n        \"schema\": \"agent_poc\",\n        \"metric_view_prefix\": \"mv_\"\n    }\n)\n\nprint(\"‚úÖ Sequential Enhancer initialized (with metric view support)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze all failures and group fixes by type\n",
    "print(\"Analyzing failures and generating fixes...\")\n",
    "print(\"(LLM will analyze each failure)\\n\")\n",
    "\n",
    "grouped_fixes = sequential_enhancer.analyze_all_failures(\n",
    "    benchmark_results=initial_results,\n",
    "    space_config=initial_config\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FIXES GENERATED (Grouped by Type)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "total_fixes = 0\n",
    "for category, fixes in grouped_fixes.items():\n",
    "    count = len(fixes)\n",
    "    total_fixes += count\n",
    "    print(f\"\\n{category.upper()}: {count} fixes\")\n",
    "    for i, fix in enumerate(fixes, 1):\n",
    "        fix_type = fix.get('type', 'unknown')\n",
    "        print(f\"  {i}. {fix_type}\")\n",
    "        if fix_type == 'add_synonym':\n",
    "            print(f\"     {fix['table']}.{fix['column']} ‚Üí '{fix['synonym']}'\")\n",
    "        elif fix_type == 'add_column_description':\n",
    "            print(f\"     {fix['table']}.{fix['column']}\")\n",
    "        elif fix_type == 'add_example_query':\n",
    "            print(f\"     Pattern: {fix.get('pattern_name', 'N/A')}\")\n",
    "        elif fix_type == 'create_metric_view':\n",
    "            print(f\"     {fix['catalog']}.{fix['schema']}.{fix['metric_view_name']}\")\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(f\"TOTAL FIXES: {total_fixes}\")\n",
    "print(f\"{'=' * 80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Sequential Fix Application\n",
    "\n",
    "Apply fixes **one at a time**:\n",
    "1. Apply fix to dev-working\n",
    "2. Wait for indexing\n",
    "3. Evaluate benchmarks\n",
    "4. If improved ‚Üí Update dev-best\n",
    "5. If not improved ‚Üí Rollback from dev-best\n",
    "\n",
    "‚ö†Ô∏è **This will take ~40 minutes for a full loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for sequential loop\n",
    "INDEXING_WAIT_TIME = 60  # seconds to wait after each change\n",
    "DRY_RUN = True  # Set to False to actually apply changes\n",
    "\n",
    "if DRY_RUN:\n",
    "    print(\"‚ö†Ô∏è DRY RUN MODE - Changes will NOT be applied\")\n",
    "    print(\"Set DRY_RUN = False to run the sequential loop\")\n",
    "else:\n",
    "    print(\"‚ùó LIVE MODE - Changes WILL be applied to dev-working\")\n",
    "    print(f\"Indexing wait time: {INDEXING_WAIT_TIME}s\")\n",
    "    print(f\"Estimated time: ~{total_fixes * (INDEXING_WAIT_TIME + 30) / 60:.0f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run sequential enhancement loop\n",
    "if not DRY_RUN and total_fixes > 0:\n",
    "    print(\"Starting Sequential Enhancement Loop...\")\n",
    "    print(f\"This will apply {total_fixes} fixes one at a time.\\n\")\n",
    "    \n",
    "    loop_result = sequential_enhancer.run_sequential_loop(\n",
    "        benchmarks=benchmarks,\n",
    "        grouped_fixes=grouped_fixes,\n",
    "        indexing_wait_time=INDEXING_WAIT_TIME\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"SEQUENTIAL LOOP RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Initial Score: {loop_result['initial_score']:.1%}\")\n",
    "    print(f\"Final Score: {loop_result['final_score']:.1%}\")\n",
    "    print(f\"Improvement: {loop_result['final_score'] - loop_result['initial_score']:+.1%}\")\n",
    "    print(f\"Fixes Applied: {len(loop_result['fixes_applied'])}\")\n",
    "    print(f\"Fixes Rejected: {len(loop_result['fixes_rejected'])}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Sequential loop skipped (DRY_RUN=True or no fixes)\")\n",
    "    loop_result = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show detailed history (if loop was run)\n",
    "if loop_result and loop_result.get('history'):\n",
    "    print(\"\\nFix Application History:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    history_df = pd.DataFrame(loop_result['history'])\n",
    "    display_cols = ['fix_category', 'fix_type', 'score_before', 'score_after', 'accepted']\n",
    "    display(history_df[display_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Final Results & Decision\n",
    "\n",
    "Now you can decide:\n",
    "1. **Promote** dev-best to production\n",
    "2. **Keep** all spaces for review\n",
    "3. **Delete** dev spaces (no promotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of three spaces\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"THREE-SPACE STATUS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nProduction (unchanged): {PRODUCTION_ID}\")\n",
    "print(f\"Dev-Working (test space): {DEV_WORKING_ID}\")\n",
    "print(f\"Dev-Best (best config): {DEV_BEST_ID}\")\n",
    "\n",
    "if loop_result:\n",
    "    print(f\"\\nBest Score Achieved: {loop_result['final_score']:.1%}\")\n",
    "else:\n",
    "    print(f\"\\nInitial Score: {initial_results['score']:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 1: Promote dev-best to production\n",
    "PROMOTE_TO_PRODUCTION = False  # Set to True to promote\n",
    "\n",
    "if PROMOTE_TO_PRODUCTION:\n",
    "    print(\"Promoting dev-best configuration to production...\")\n",
    "    result = space_cloner.promote_to_production()\n",
    "    if result['success']:\n",
    "        print(\"‚úÖ Production updated with best configuration!\")\n",
    "    else:\n",
    "        print(f\"‚ùå Promotion failed: {result['error']}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Promotion skipped (PROMOTE_TO_PRODUCTION=False)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 2: Keep all spaces for review\n",
    "print(\"\\nTo keep all spaces for manual review, do nothing.\")\n",
    "print(f\"\\nYou can access:\")\n",
    "print(f\"  - Production: https://{DATABRICKS_HOST}/genie/spaces/{PRODUCTION_ID}\")\n",
    "print(f\"  - Dev-Working: https://{DATABRICKS_HOST}/genie/spaces/{DEV_WORKING_ID}\")\n",
    "print(f\"  - Dev-Best: https://{DATABRICKS_HOST}/genie/spaces/{DEV_BEST_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 3: Delete dev spaces (cleanup)\n",
    "CLEANUP_DEV_SPACES = False  # Set to True to delete dev spaces\n",
    "\n",
    "if CLEANUP_DEV_SPACES:\n",
    "    print(\"Deleting dev spaces...\")\n",
    "    result = space_cloner.cleanup_dev_spaces()\n",
    "    if result['success']:\n",
    "        print(f\"‚úÖ Deleted: {result['deleted']}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Cleanup issues: {result['error']}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Cleanup skipped (CLEANUP_DEV_SPACES=False)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Debug Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a single fix manually\n",
    "def test_single_fix(fix: dict):\n",
    "    \"\"\"Apply a single fix and evaluate.\"\"\"\n",
    "    print(f\"Testing fix: {fix.get('type')}\")\n",
    "    \n",
    "    # Get current config\n",
    "    current_config = space_cloner.get_dev_working_config()\n",
    "    \n",
    "    # Apply fix\n",
    "    new_config = sequential_enhancer._apply_single_fix(current_config, fix)\n",
    "    \n",
    "    # Show diff\n",
    "    print(\"\\nConfig changes:\")\n",
    "    print(json.dumps(fix, indent=2))\n",
    "    \n",
    "    return new_config\n",
    "\n",
    "# Example: Test first metadata fix\n",
    "# if grouped_fixes.get('metadata'):\n",
    "#     test_single_fix(grouped_fixes['metadata'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate current dev-working config\n",
    "def validate_dev_working():\n",
    "    \"\"\"Validate the dev-working space configuration.\"\"\"\n",
    "    space_updater = SpaceUpdater(DATABRICKS_HOST, DATABRICKS_TOKEN)\n",
    "    config = space_cloner.get_dev_working_config()\n",
    "    validation = space_updater.validate_config(config)\n",
    "    \n",
    "    print(\"\\nDev-Working Validation:\")\n",
    "    print(f\"  Valid: {'‚úÖ' if validation['is_valid'] else '‚ùå'}\")\n",
    "    \n",
    "    if validation['errors']:\n",
    "        print(f\"  Errors: {len(validation['errors'])}\")\n",
    "        for e in validation['errors'][:5]:\n",
    "            print(f\"    - {e}\")\n",
    "    \n",
    "    if validation['warnings']:\n",
    "        print(f\"  Warnings: {len(validation['warnings'])}\")\n",
    "    \n",
    "    return validation\n",
    "\n",
    "validate_dev_working()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fixes to JSON for review\n",
    "if grouped_fixes:\n",
    "    output_file = \"debug_fixes_v2.json\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(grouped_fixes, f, indent=2, default=str)\n",
    "    print(f\"‚úÖ Fixes saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Next Steps\n",
    "\n",
    "After testing in this notebook:\n",
    "\n",
    "1. ‚úÖ Verify three-space architecture works\n",
    "2. ‚úÖ Check fix generation (4 types only)\n",
    "3. ‚úÖ Test sequential application with DRY_RUN=False\n",
    "4. ‚úÖ Decide on promotion to production\n",
    "\n",
    "Then move to the **Streamlit App** for interactive use:\n",
    "```bash\n",
    "streamlit run databricks_apps/interactive_enhancement_app.py\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}