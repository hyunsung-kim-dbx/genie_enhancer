{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genie Enhancement v3 - Debug Notebook\n",
    "\n",
    "## 4-Stage Batch Apply Flow\n",
    "\n",
    "This notebook tests the v3 enhancement workflow:\n",
    "\n",
    "1. **Score** - Evaluate benchmarks on Genie Space\n",
    "2. **Plan** - Analyze failures, generate ALL fixes\n",
    "3. **Apply** - Apply ALL fixes in ONE batch update\n",
    "4. **Validate** - Re-score and check improvement\n",
    "\n",
    "## Key Difference from v2\n",
    "- v2: Apply fixes one-at-a-time with rollback\n",
    "- v3: Apply ALL fixes at once (batch)\n",
    "\n",
    "## Usage\n",
    "Run cells in order. Each section can be debugged independently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project path setup\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Find project root\n",
    "current_path = Path(os.getcwd())\n",
    "if current_path.name == 'genie_enhancer':\n",
    "    project_root = current_path\n",
    "else:\n",
    "    project_root = current_path\n",
    "    while project_root.name != 'genie_enhancer' and project_root != project_root.parent:\n",
    "        project_root = project_root.parent\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test imports from lib/\n",
    "try:\n",
    "    from lib.genie_client import GenieConversationalClient\n",
    "    print(\"‚úÖ lib.genie_client\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå lib.genie_client: {e}\")\n",
    "\n",
    "try:\n",
    "    from lib.space_api import SpaceUpdater\n",
    "    print(\"‚úÖ lib.space_api\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå lib.space_api: {e}\")\n",
    "\n",
    "try:\n",
    "    from lib.scorer import BenchmarkScorer\n",
    "    print(\"‚úÖ lib.scorer\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå lib.scorer: {e}\")\n",
    "\n",
    "try:\n",
    "    from lib.benchmark_parser import BenchmarkLoader\n",
    "    print(\"‚úÖ lib.benchmark_parser\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå lib.benchmark_parser: {e}\")\n",
    "\n",
    "try:\n",
    "    from lib.llm import DatabricksLLMClient\n",
    "    print(\"‚úÖ lib.llm\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå lib.llm: {e}\")\n",
    "\n",
    "try:\n",
    "    from lib.sql import SQLExecutor\n",
    "    print(\"‚úÖ lib.sql\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå lib.sql: {e}\")\n",
    "\n",
    "try:\n",
    "    from lib.enhancer import EnhancementPlanner\n",
    "    print(\"‚úÖ lib.enhancer\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå lib.enhancer: {e}\")\n",
    "\n",
    "try:\n",
    "    from lib.applier import BatchApplier\n",
    "    print(\"‚úÖ lib.applier\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå lib.applier: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full imports\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from lib.genie_client import GenieConversationalClient\n",
    "from lib.space_api import SpaceUpdater\n",
    "from lib.scorer import BenchmarkScorer\n",
    "from lib.benchmark_parser import BenchmarkLoader\n",
    "from lib.llm import DatabricksLLMClient\n",
    "from lib.sql import SQLExecutor\n",
    "from lib.enhancer import EnhancementPlanner\n",
    "from lib.applier import BatchApplier\n",
    "\n",
    "print(\"‚úÖ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === UPDATE THESE VALUES ===\n",
    "DATABRICKS_HOST = \"your-workspace.cloud.databricks.com\"\n",
    "DATABRICKS_TOKEN = \"YOUR_TOKEN_HERE\"\n",
    "GENIE_SPACE_ID = \"your-space-id\"\n",
    "WAREHOUSE_ID = \"your-warehouse-id\"  # For metric views\n",
    "LLM_ENDPOINT = \"databricks-claude-sonnet-4\"\n",
    "\n",
    "# Target score\n",
    "TARGET_SCORE = 0.90\n",
    "\n",
    "print(f\"Host: {DATABRICKS_HOST}\")\n",
    "print(f\"Space ID: {GENIE_SPACE_ID}\")\n",
    "print(f\"Warehouse: {WAREHOUSE_ID}\")\n",
    "print(f\"LLM: {LLM_ENDPOINT}\")\n",
    "print(f\"Target: {TARGET_SCORE:.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Initialize Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genie Client\n",
    "print(\"Initializing Genie Client...\")\n",
    "genie_client = GenieConversationalClient(\n",
    "    host=DATABRICKS_HOST,\n",
    "    token=DATABRICKS_TOKEN,\n",
    "    space_id=GENIE_SPACE_ID\n",
    ")\n",
    "print(\"‚úÖ Genie Client initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Client\n",
    "print(\"Initializing LLM Client...\")\n",
    "llm_client = DatabricksLLMClient(\n",
    "    host=DATABRICKS_HOST,\n",
    "    token=DATABRICKS_TOKEN,\n",
    "    endpoint_name=LLM_ENDPOINT\n",
    ")\n",
    "\n",
    "if llm_client.test_connection():\n",
    "    print(\"‚úÖ LLM Client connected\")\n",
    "else:\n",
    "    print(\"‚ùå LLM connection failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space API (for export/import)\n",
    "print(\"Initializing Space API...\")\n",
    "space_api = SpaceUpdater(\n",
    "    host=DATABRICKS_HOST,\n",
    "    token=DATABRICKS_TOKEN\n",
    ")\n",
    "print(\"‚úÖ Space API initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL Executor (for metric views)\n",
    "print(\"Initializing SQL Executor...\")\n",
    "sql_executor = SQLExecutor(\n",
    "    host=DATABRICKS_HOST,\n",
    "    token=DATABRICKS_TOKEN,\n",
    "    warehouse_id=WAREHOUSE_ID\n",
    ")\n",
    "print(\"‚úÖ SQL Executor initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark Scorer\n",
    "print(\"Initializing Scorer...\")\n",
    "scorer = BenchmarkScorer(\n",
    "    genie_client=genie_client,\n",
    "    llm_client=llm_client,\n",
    "    sql_executor=sql_executor,\n",
    "    config={\"question_timeout\": 120}\n",
    ")\n",
    "print(\"‚úÖ Scorer initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Load Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load benchmarks\n",
    "benchmark_file = project_root / \"benchmarks\" / \"benchmarks.json\"\n",
    "print(f\"Loading from: {benchmark_file}\")\n",
    "\n",
    "loader = BenchmarkLoader(str(benchmark_file))\n",
    "all_benchmarks = loader.load()\n",
    "print(f\"‚úÖ Loaded {len(all_benchmarks)} benchmarks\")\n",
    "\n",
    "# Show first few\n",
    "for i, b in enumerate(all_benchmarks[:3]):\n",
    "    print(f\"  {i+1}. {b['question'][:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Filter for faster testing\n",
    "USE_SUBSET = True  # Set to False for full run\n",
    "\n",
    "if USE_SUBSET:\n",
    "    benchmarks = all_benchmarks[:5]  # First 5 only\n",
    "    print(f\"‚ö†Ô∏è TEST MODE: Using {len(benchmarks)} benchmarks\")\n",
    "else:\n",
    "    benchmarks = all_benchmarks\n",
    "    print(f\"FULL MODE: Using {len(benchmarks)} benchmarks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# STAGE 1: SCORE\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run scoring\n",
    "print(\"=\"*60)\n",
    "print(\"STAGE 1: SCORING BENCHMARKS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = datetime.now()\n",
    "score_results = scorer.score(benchmarks)\n",
    "duration = (datetime.now() - start_time).total_seconds()\n",
    "\n",
    "print(f\"\\nScore: {score_results['score']:.1%}\")\n",
    "print(f\"Passed: {score_results['passed']}/{score_results['total']}\")\n",
    "print(f\"Duration: {duration:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show failed benchmarks\n",
    "failed_results = [r for r in score_results['results'] if not r['passed']]\n",
    "\n",
    "print(f\"\\n‚ùå Failed Benchmarks ({len(failed_results)}):\\n\")\n",
    "for i, r in enumerate(failed_results, 1):\n",
    "    print(f\"{i}. {r['question'][:60]}...\")\n",
    "    print(f\"   Category: {r.get('failure_category', 'unknown')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# STAGE 2: PLAN\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current space config\n",
    "print(\"Exporting current space config...\")\n",
    "space_config = space_api.export_space(GENIE_SPACE_ID)\n",
    "print(f\"‚úÖ Config loaded\")\n",
    "print(f\"   Tables: {len(space_config.get('data_sources', {}).get('tables', []))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Enhancement Planner\n",
    "print(\"Initializing Enhancement Planner...\")\n",
    "prompts_dir = project_root / \"prompts\"\n",
    "planner = EnhancementPlanner(llm_client, prompts_dir)\n",
    "print(\"‚úÖ Planner initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate enhancement plan\n",
    "print(\"=\"*60)\n",
    "print(\"STAGE 2: GENERATING ENHANCEMENT PLAN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "grouped_fixes = planner.generate_plan(\n",
    "    failed_benchmarks=failed_results,\n",
    "    space_config=space_config,\n",
    "    parallel_workers=2  # Reduce for debugging\n",
    ")\n",
    "\n",
    "total_fixes = sum(len(f) for f in grouped_fixes.values())\n",
    "print(f\"\\n‚úÖ Generated {total_fixes} fixes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show fixes by category\n",
    "print(\"\\nFixes by Category:\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "for category in [\"metric_view\", \"metadata\", \"sample_query\", \"instruction\"]:\n",
    "    fixes = grouped_fixes.get(category, [])\n",
    "    print(f\"\\n{category.upper()} ({len(fixes)} fixes)\")\n",
    "    for i, fix in enumerate(fixes[:5], 1):  # Show first 5\n",
    "        fix_type = fix.get('type', 'unknown')\n",
    "        if fix_type == 'add_synonym':\n",
    "            print(f\"  {i}. {fix_type}: {fix.get('table')}.{fix.get('column')} ‚Üí '{fix.get('synonym')}'\")\n",
    "        elif fix_type == 'add_column_description':\n",
    "            print(f\"  {i}. {fix_type}: {fix.get('table')}.{fix.get('column')}\")\n",
    "        else:\n",
    "            print(f\"  {i}. {fix_type}\")\n",
    "    if len(fixes) > 5:\n",
    "        print(f\"  ... and {len(fixes)-5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# STAGE 3: APPLY (Batch)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Batch Applier\n",
    "print(\"Initializing Batch Applier...\")\n",
    "applier = BatchApplier(\n",
    "    space_api=space_api,\n",
    "    sql_executor=sql_executor,\n",
    "    config={\n",
    "        \"catalog\": \"sandbox\",\n",
    "        \"schema\": \"genie_enhancement\"\n",
    "    }\n",
    ")\n",
    "print(\"‚úÖ Applier initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRY RUN first\n",
    "DRY_RUN = True  # Set to False to actually apply\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"STAGE 3: APPLY ALL FIXES {'(DRY RUN)' if DRY_RUN else '(LIVE)'}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "apply_result = applier.apply_all(\n",
    "    space_id=GENIE_SPACE_ID,\n",
    "    grouped_fixes=grouped_fixes,\n",
    "    dry_run=DRY_RUN\n",
    ")\n",
    "\n",
    "print(f\"\\nApplied: {len(apply_result['applied'])}\")\n",
    "print(f\"Failed: {len(apply_result['failed'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show applied fixes\n",
    "print(\"\\n‚úÖ Applied Fixes:\")\n",
    "for i, fix in enumerate(apply_result['applied'][:10], 1):\n",
    "    print(f\"  {i}. {fix.get('type')}\")\n",
    "\n",
    "if apply_result['failed']:\n",
    "    print(\"\\n‚ùå Failed Fixes:\")\n",
    "    for i, fix in enumerate(apply_result['failed'], 1):\n",
    "        print(f\"  {i}. {fix.get('type')}: {fix.get('error')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIVE RUN (uncomment to execute)\n",
    "# WARNING: This will modify your Genie Space!\n",
    "\n",
    "# print(\"Applying fixes for real...\")\n",
    "# apply_result = applier.apply_all(\n",
    "#     space_id=GENIE_SPACE_ID,\n",
    "#     grouped_fixes=grouped_fixes,\n",
    "#     dry_run=False\n",
    "# )\n",
    "# print(f\"Applied: {len(apply_result['applied'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# STAGE 4: VALIDATE\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for Genie indexing (only if not dry run)\n",
    "INDEXING_WAIT = 60  # seconds\n",
    "\n",
    "if not DRY_RUN and len(apply_result['applied']) > 0:\n",
    "    print(f\"Waiting {INDEXING_WAIT}s for Genie indexing...\")\n",
    "    time.sleep(INDEXING_WAIT)\n",
    "    print(\"‚úÖ Wait complete\")\n",
    "else:\n",
    "    print(\"Skipping wait (dry run or no changes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-score benchmarks\n",
    "print(\"=\"*60)\n",
    "print(\"STAGE 4: VALIDATING RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "final_results = scorer.score(benchmarks)\n",
    "\n",
    "initial_score = score_results['score']\n",
    "final_score = final_results['score']\n",
    "improvement = final_score - initial_score\n",
    "\n",
    "print(f\"\\nInitial Score: {initial_score:.1%}\")\n",
    "print(f\"Final Score:   {final_score:.1%}\")\n",
    "print(f\"Improvement:   {improvement:+.1%}\")\n",
    "print(f\"Target:        {TARGET_SCORE:.1%}\")\n",
    "print()\n",
    "if final_score >= TARGET_SCORE:\n",
    "    print(\"üéâ TARGET REACHED!\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Need another loop (gap: {TARGET_SCORE - final_score:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Debug Utilities\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Genie API directly\n",
    "test_question = \"What tables are available?\"\n",
    "print(f\"Testing Genie: {test_question}\")\n",
    "\n",
    "response = genie_client.ask(test_question, timeout=60)\n",
    "print(f\"Status: {response['status']}\")\n",
    "if response.get('sql'):\n",
    "    print(f\"SQL: {response['sql'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test LLM directly\n",
    "test_prompt = \"Say 'Hello, Genie Enhancement is working!'\"\n",
    "print(f\"Testing LLM...\")\n",
    "\n",
    "response = llm_client.generate(test_prompt, max_tokens=50)\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export current config to JSON\n",
    "output_file = \"debug_space_config.json\"\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(space_config, f, indent=2)\n",
    "print(f\"‚úÖ Config saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export fixes to JSON\n",
    "output_file = \"debug_fixes.json\"\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(grouped_fixes, f, indent=2, default=str)\n",
    "print(f\"‚úÖ Fixes saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
